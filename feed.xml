<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:yandex="http://news.yandex.ru"
     xmlns:media="http://search.yahoo.com/mrss/"
     xmlns:turbo="http://turbo.yandex.ru"
     version="2.0">
    <channel>
        <title>Hexlet Guides</title>
        <link>https://guides.hexlet.io/</link>
        <description>Полезные статьи и гайды для разработчиков
</description>
        <language>ru</language>
        <!-- <turbo:analytics></turbo:analytics> -->
        <!-- <turbo:adNetwork></turbo:adNetwork> -->
        
        
        <item turbo="true">
            <turbo:extendedHtml>true</turbo:extendedHtml>
            <link>https://guides.hexlet.io/makefile-as-task-runner/</link>
            <!-- <turbo:source></turbo:source> -->
            <!-- <turbo:topic>What Is a Makefile and How to Use It</turbo:topic> -->
            <title>What Is a Makefile and How to Use It</title>
            <pubDate>Fri, 10 Jun 2022 00:00:00 +0000</pubDate>
            <author>Kirill Mokevnin</author>
            <!-- <yandex:related></yandex:related> -->
            <turbo:content>
              <![CDATA[
                <div data-block="breadcrumblist">
                  <a href="https://guides.hexlet.io/">Hexlet Guides</a>
                  <a href="https://guides.hexlet.io/makefile-as-task-runner/">What Is a Makefile and How to Use It</a>
                </div>
                <button
                  formaction="https://guides.hexlet.io/makefile-as-task-runner/"
                  data-background-color="#eee"
                  data-color="dark"
                  data-turbo="false"
                  data-primary="false"
                >
                  Читать полную версию на сайте
                </button>
                <h2 id="introduction">Introduction</h2>

<p>Many developers may recall the first day they started working on a new project. After cloning the main repository, there comes a point when you have to enter a lot of commands with certain flags and in a specific order. In most cases, it’s hard to grasp what is going on without a description of the commands. For example:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Bash</span>
<span class="nb">touch</span> ~/.bash_history
ufw allow 3035/tcp <span class="o">||</span> <span class="nb">echo</span> <span class="s1">'cant configure ufw'</span>
ufw allow http <span class="o">||</span> <span class="nb">echo</span> <span class="s1">'cant configure ufw'</span>
docker run <span class="se">\</span>
  <span class="nt">-v</span> /root/:/root/ <span class="se">\</span>
  <span class="nt">-v</span> /etc:/etc <span class="se">\</span>
  <span class="nt">-v</span> /var/run/docker.sock:/var/run/docker.sock <span class="se">\</span>
  <span class="nt">-v</span> /var/tmp:/var/tmp <span class="se">\</span>
  <span class="nt">-v</span> /tmp:/tmp <span class="se">\</span>
  <span class="nt">-v</span> <span class="nv">$PWD</span>:/app <span class="se">\</span>
  <span class="nt">--network</span> host <span class="se">\</span>
  <span class="nt">-w</span> /app <span class="se">\</span>
  <span class="nt">--env-file</span> .env <span class="se">\</span>
  ansible ansible-playbook ansible/development.yml <span class="nt">-i</span> ansible/development <span class="nt">--limit</span><span class="o">=</span>localhost <span class="nt">-vv</span>
<span class="nb">grep</span> <span class="nt">-qxF</span> <span class="s1">'fs.inotify.max_user_watches=524288'</span> /etc/sysctl.conf <span class="o">||</span> <span class="nb">echo </span>fs.inotify.max_user_watches<span class="o">=</span>524288 | <span class="nb">tee</span> <span class="nt">-a</span> /etc/sysctl.conf <span class="o">||</span> <span class="nb">echo</span> <span class="s1">'cant set max_user_watches'</span> <span class="o">&amp;&amp;</span> sysctl <span class="nt">-p</span>
<span class="nb">sudo </span>systemctl daemon-reload <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>systemctl restart docker
</code></pre></div></div>

<p>These commands are just a small portion of the project deployment process. The commands themselves are extensive and contain several flags, as shown in the example above, making them not only difficult to learn but also difficult to enter manually. Constantly maintaining documentation becomes more challenging as the project grows; it inevitably becomes outdated, and the entry barrier for newcomers increases since no one can remember all of the project’s details. Some of these commands must be used on a daily basis, if not multiple times per day.</p>

<p>Over time, it became clear that we desperately needed a tool that could maintain such commands, and provide convenient shortcuts and self-documentation of the project. This is precisely what <em>Makefile</em> and the <code class="language-plaintext highlighter-rouge">make</code> utility have turned into. In this guide, I’ll show you how to reduce the deployment to a few short and straightforward commands using these tools:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Bash</span>
make setup
make start
make <span class="nb">test</span>
</code></pre></div></div>

<h2 id="what-is-make-and-makefile">What is <code class="language-plaintext highlighter-rouge">make</code> and <em>Makefile</em></h2>

<p><em>Makefile</em> is a file that is stored in the repository alongside the code. It is usually placed at the project’s root. It acts both as documentation and as executable code. The Makefile hides the implementation details and manages the commands, and the <code class="language-plaintext highlighter-rouge">make</code> utility runs them from the Makefile in the current directory.</p>

<p><code class="language-plaintext highlighter-rouge">make</code> was originally designed to automate the building process of executable programs and libraries from source code. Most *nix distributions have it by default, which has contributed to its extensive use. Later, it turned out that this tool is convenient to use in other development projects because the process is essentially the same in most cases - automation and building applications.</p>

<p>The <code class="language-plaintext highlighter-rouge">make</code> has become a standard for many developers, especially for those working on large projects. Examples of makefile can be found in projects such as <a href="https://github.com/kubernetes/kubernetes/blob/master/build/root/Makefile">Kubernetes</a>, <a href="https://github.com/babel/babel/blob/main/Makefile">Babel</a>, <a href="https://github.com/ansible/ansible/blob/devel/Makefile">Ansible</a>, and, of course, everywhere on <a href="https://github.com/Hexlet">Hexlet</a>.</p>

<h3 id="makefile-syntax"><em>Makefile</em> syntax</h3>

<p><code class="language-plaintext highlighter-rouge">make</code> runs targets from a <em>Makefile</em> that contains the following commands:</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nl">target1</span><span class="o">:</span> <span class="c">#</span><span class="nf"> target name</span><span class="p">,</span><span class="nf"> you can also use kebab-case or snake_case</span>
	command1 <span class="c"># it's very important to use tabs to indent </span>
	command2 <span class="c"># the commands will be executed sequentially and only if the previous one was successful</span>
</code></pre></div></div>

<p>However, it’s not enough to just start using a Makefile in a project. To make its implementation more efficient, build a target-oriented command structure and give the targets semantically relevant names. At first, moving commands to a Makefile may result in all commands being merged into a single one with a vague name:</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nl">up</span><span class="o">:</span> <span class="c">#</span><span class="nf"> deploying and launching</span>
	<span class="nb">cp</span> <span class="nt">-n</span> .env.example .env
	<span class="nb">touch </span>database/database.sqlite
	composer <span class="nb">install</span>
	npm <span class="nb">install</span>
	php artisan key:generate
	php artisan migrate <span class="nt">--seed</span>
	heroku <span class="nb">local</span> <span class="nt">-f</span> Procfile.dev <span class="c"># project launch</span>
</code></pre></div></div>

<p>Several actions take place here at once: creating a file with environment variables, preparing the database, generating keys, installing dependencies, and launching the project. Since this is impossible to understand from the comments and target name, it’s best to separate these  commands into different independent targets:</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nl">env-prepare</span><span class="o">:</span> <span class="c">#</span><span class="nf"> create .env file for secrets</span>
	<span class="nb">cp</span> <span class="nt">-n</span> .env.example .env

<span class="nl">sqlite-prepare</span><span class="o">:</span> <span class="c">#</span><span class="nf"> prepare a local database</span>
	<span class="nb">touch </span>database/database.sqlite

<span class="nl">install</span><span class="o">:</span> <span class="c">#</span><span class="nf"> install dependencies</span>
	composer <span class="nb">install</span>
	npm <span class="nb">install</span>

<span class="nl">key</span><span class="o">:</span> <span class="c">#</span><span class="nf"> generate keys</span>
	php artisan key:generate

<span class="nl">db-prepare</span><span class="o">:</span> <span class="c">#</span><span class="nf"> upload data to the database</span>
	php artisan migrate <span class="nt">--seed</span>

<span class="nl">start</span><span class="o">:</span> <span class="c">#</span><span class="nf"> run the app</span>
	heroku <span class="nb">local</span> <span class="nt">-f</span> Procfile.dev
</code></pre></div></div>

<p>Now that the commands are divided into targets, you can individually install dependencies with the <code class="language-plaintext highlighter-rouge">make install</code> command or run your app via <code class="language-plaintext highlighter-rouge">make start</code>. But the remaining targets are only required during the project’s initial deployment and must be performed in a specific sequence. In the Makefile world, the target has the following prerequisites:</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nl">target1</span><span class="o">:</span> <span class="nf">target2 </span><span class="c">#</span><span class="nf"> here established the command dependency</span><span class="p">,</span><span class="nf"> target1 depends on target2</span>
	command2 <span class="c"># target2 will be executed only if target2 command was successful</span>

<span class="nl">target2</span><span class="o">:</span>
	command1
</code></pre></div></div>

<p>Commands will only be executed in the specified order and only if the previous command proves to be successful. Therefore, you can add a <code class="language-plaintext highlighter-rouge">setup</code> target to combine all the necessary actions:</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nl">setup</span><span class="o">:</span> <span class="nf">env-prepare sqlite-prepare install key db-prepare </span><span class="c">#</span><span class="nf"> you may refer to the targets described below</span>

<span class="nl">env-prepare</span><span class="o">:</span>
	<span class="nb">cp</span> <span class="nt">-n</span> .env.example .env

<span class="nl">sqlite-prepare</span><span class="o">:</span>
	<span class="nb">touch </span>database/database.sqlite

<span class="nl">install</span><span class="o">:</span>
	composer <span class="nb">install</span>
	npm <span class="nb">install</span>

<span class="nl">key</span><span class="o">:</span>
	php artisan key:generate

<span class="nl">db-prepare</span><span class="o">:</span>
	php artisan migrate <span class="nt">--seed</span>

<span class="nl">start</span><span class="o">:</span>
	heroku <span class="nb">local</span> <span class="nt">-f</span> Procfile.dev
</code></pre></div></div>

<p>Now it is enough to deploy and launch the project with two commands:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Bash</span>
make setup <span class="c"># will run sequentially: env-prepare sqlite-prepare install key db-prepare</span>
make start
</code></pre></div></div>

<p>The project commands and flags are combined into a <em>Makefile</em> as a result of the <em>Makefile’s</em> work. It ensures the correct execution order, regardless of the languages or technologies involved.</p>

<h2 id="advanced-usage">Advanced usage</h2>

<h3 id="fake-target">Fake target</h3>

<p>Using <code class="language-plaintext highlighter-rouge">make</code> in a project may one day lead to the error <code class="language-plaintext highlighter-rouge">make: &lt;target name&gt; is up to date.</code>, although everything is written correctly. This is frequently related to the existence of a directory or file that matches the target name. For example:</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nl">test</span><span class="o">:</span> <span class="c">#</span><span class="nf"> the target in the makefile</span>
	php artisan <span class="nb">test</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Bash</span>
<span class="nv">$ </span><span class="nb">ls
</span>Makefile
<span class="nb">test</span> <span class="c"># the file system contains a directory with the name of the target in the makefile</span>

<span class="nv">$ </span>make <span class="nb">test</span> <span class="c"># an attempt to run tests</span>
make: <span class="sb">`</span><span class="nb">test</span><span class="sb">`</span> is up to date.
</code></pre></div></div>

<p>As stated previously, <code class="language-plaintext highlighter-rouge">make</code> was designed to build programs from source code. Therefore, it searches for a directory or file with the given name and attempts to create a project from it. To alter this behavior, you need to add a <code class="language-plaintext highlighter-rouge">.PHONY</code> pointer to the target at the end of the Makefile:</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nl">test</span><span class="o">:</span>
	php artisan <span class="nb">test</span>

<span class="nl">.PHONY</span><span class="o">:</span> <span class="nf">test</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Bash</span>
<span class="nv">$ </span>make <span class="nb">test</span>
✓ All tests passed!
</code></pre></div></div>

<h3 id="running-commands-consecutively-and-ignoring-errors">Running commands consecutively and ignoring errors</h3>

<p>You can run commands one at a time: <code class="language-plaintext highlighter-rouge">make setup</code>, <code class="language-plaintext highlighter-rouge">make start</code>, <code class="language-plaintext highlighter-rouge">make test</code> or all at once, space-separated: <code class="language-plaintext highlighter-rouge">make setup start test</code>. The latter method works as a dependency between commands, although it is not documented in the Makefile. Difficulties may arise if one of the commands produces an error that must be ignored. In the previous examples, such a command was to create an .env-file when deploying the project:</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nl">env-prepare</span><span class="o">:</span>
	<span class="nb">cp</span> <span class="nt">-n</span> .env.example .env <span class="c"># if the file has already been created, using this command again will result in an error</span>
</code></pre></div></div>

<p>The easiest (<em>but not the only</em>) way to “cover up” an error is to use a logical OR in the Makefile:</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nl">env-prepare</span><span class="o">:</span>
	<span class="nb">cp</span> <span class="nt">-n</span> .env.example .env <span class="o">||</span> <span class="nb">true</span> <span class="c"># any result of command execution is now considered successful</span>
</code></pre></div></div>

<p>Be cautious applying such hacks so that you don’t shoot yourself in the foot in more complex scenarios.</p>

<h3 id="variables">Variables</h3>

<p>Configuration parameters, path indicators, and environment variables are often substituted into commands, and <code class="language-plaintext highlighter-rouge">make</code> enables you to handle this as well. Variables can be written directly in the command within the makefile and passed when called:</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nl">say</span><span class="o">:</span>
	<span class="nb">echo</span> <span class="s2">"Hello, </span><span class="nv">$(HELLO)</span><span class="s2">!"</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Bash</span>
<span class="nv">$ </span>make say <span class="nv">HELLO</span><span class="o">=</span>World
<span class="nb">echo</span> <span class="s2">"Hello, World!"</span>
Hello, World!

<span class="nv">$ </span>make say <span class="nv">HELLO</span><span class="o">=</span>Kitty
<span class="nb">echo</span> <span class="s2">"Hello, Kitty!"</span>
Hello, Kitty!
</code></pre></div></div>

<p>Variables can be optional and have a default value. They are commonly declared at the beginning of the Makefile.</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nv">HELLO</span><span class="o">?=</span>World <span class="c"># the question mark indicates that the variable is optional. The value after assignment can be omitted</span>

<span class="nl">say</span><span class="o">:</span>
	<span class="nb">echo</span> <span class="s2">"Hello, </span><span class="nv">$(HELLO)</span><span class="s2">!"</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Bash</span>
<span class="nv">$ </span>make say
<span class="nb">echo</span> <span class="s2">"Hello, World!"</span>
Hello, World!

<span class="nv">$ </span>make say <span class="nv">HELLO</span><span class="o">=</span>Kitty
<span class="nb">echo</span> <span class="s2">"Hello, Kitty!"</span>
Hello, Kitty!
</code></pre></div></div>

<p>Some variables in the <em>Makefile</em> have names other than the system ones. For example, <code class="language-plaintext highlighter-rouge">$PWD</code> is referred to as <code class="language-plaintext highlighter-rouge">$CURDIR</code> in the <a href="https://github.com/hexlet-basics/hexlet_basics/blob/3f4635bf629e2676efe547c9a01c22a2573eaebd/Makefile#L35-L39">Makefile</a>:</p>

<div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Makefile
</span><span class="nl">project-env-generate</span><span class="o">:</span>
	docker run <span class="nt">--rm</span> <span class="nt">-e</span> <span class="nv">RUNNER_PLAYBOOK</span><span class="o">=</span>ansible/development.yml <span class="se">\</span>
		<span class="nt">-v</span> <span class="nv">$(CURDIR)</span>/ansible/development:/runner/inventory <span class="se">\ </span><span class="c"># </span><span class="nv">$(CURDIR)</span> is the same as <span class="nv">$PWD</span> <span class="k">in </span>the terminal
		<span class="p">-</span>v <span class="nv">$(CURDIR)</span>:/runner/project <span class="se">\</span>
		ansible/ansible-runner
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>In this guide, we covered the main features of <em>Makefile</em> and the <code class="language-plaintext highlighter-rouge">make</code> utility. A deeper understanding of this tool will reveal many of its other useful features, such as conditions, cycles, and importing files. Makefile will be a great help in standardizing generic instructions in companies where multiple projects are written by different teams at different times: <code class="language-plaintext highlighter-rouge">setup start test deploy ...</code>.</p>

<p>Because the Makefile can describe multi-line commands consecutively, it may be used as a “universal glue” between language managers and other utilities. The widespread use of this tool and its overall simplicity allows you to quickly implement it into your project without making any changes. However, Makefile can be extremely large and complicated, as shown by the following real-world applications:</p>

<ul>
  <li><a href="https://github.com/hexlet-codebattle/codebattle/blob/master/Makefile">Codebattle</a></li>
  <li><a href="https://github.com/babel/babel/blob/main/Makefile">Babel</a></li>
  <li><a href="https://github.com/kubernetes/kubernetes/blob/master/build/root/Makefile">Kubernetes</a></li>
</ul>

<h3 id="additional-materials">Additional materials</h3>

<ul>
  <li><a href="https://makefile.site">Modern Make Handbook</a> — a summary of the documentation</li>
</ul>

<p>Makefile examples from this guide were taken from:</p>

<ul>
  <li><a href="https://github.com/Hexlet/hexlet-sicp/blob/master/Makefile">Hexlet SICP</a></li>
  <li><a href="https://github.com/hexlet-basics/hexlet_basics/blob/master/Makefile">Hexlet Basics</a></li>
</ul>

              ]]>
            </turbo:content>
        </item>
        
        <item turbo="true">
            <turbo:extendedHtml>true</turbo:extendedHtml>
            <link>https://guides.hexlet.io/learning/</link>
            <!-- <turbo:source></turbo:source> -->
            <!-- <turbo:topic>How to Learn and Cope with Negative Thoughts</turbo:topic> -->
            <title>How to Learn and Cope with Negative Thoughts</title>
            <pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate>
            <author>Rakhim Davletkaliyev</author>
            <!-- <yandex:related></yandex:related> -->
            <turbo:content>
              <![CDATA[
                <div data-block="breadcrumblist">
                  <a href="https://guides.hexlet.io/">Hexlet Guides</a>
                  <a href="https://guides.hexlet.io/learning/">How to Learn and Cope with Negative Thoughts</a>
                </div>
                <button
                  formaction="https://guides.hexlet.io/learning/"
                  data-background-color="#eee"
                  data-color="dark"
                  data-turbo="false"
                  data-primary="false"
                >
                  Читать полную версию на сайте
                </button>
                <p>Fitting active and regular exercise into your daily schedule may seem difficult, at first your body will resist: aching muscle pain, fatigue, unwillingness to continue. If you go for a run for the first time in decades, the body will clearly tell you: “you don’t need to do this”. This is a natural reaction. An evolutionary defense tool against overloads and hazards.</p>

<p>Any physical exercises or sports classes teach people to cope with this reaction and create their workout routine by listening to their body needs.</p>

<p>If you start active and regular mental exercises (for example, learning programming), then, at first, your brain will resist it. The brain has much more resistance tools than the muscles: it can plant thoughts that you’re incompetent, that “this is not mine, and it’s better for me to do something else,” or “I don’t have a mathematical mindset” and so on.</p>

<p>This article is about mental resistance to problems and how to overcome them. It consists of four steps:</p>

<ol>
  <li><strong>Self-awareness.</strong> Notice, be aware, become a scientist</li>
  <li><strong>Mindset.</strong> Understand what success depends on</li>
  <li><strong>Openness.</strong> Exclude one of the main conditions of mental block</li>
  <li><strong>Progress</strong>. Accept the realities of the learning process.</li>
</ol>

<h2 id="step-1-self-awareness">Step 1: Self-awareness</h2>

<p>First of all, it’s necessary to sharpen your awareness of emerging mental resistance. Treat your body and mind as a scientific experiment: they give you, the observer, some signals, then they react to actions and environment.</p>

<p><img src="/assets/images/learning/learning_1_en.png" alt="Мысли и их разнообразие" /></p>

<p>Try to notice or even write down the conditions under which such thoughts typically occur. A lot of things affect the mental state, including physical condition, work environment, sleep, nutrition, stress, goals, relationships, etc.</p>

<p>Keeping a journal can be a good idea. Write everything about your everyday life: how much you sleep, what you do, what you eat, how much you read, how you relax, and how is your training going.</p>

<p>It will be great if you can identify the reasons for good and bad days. Sleeping less than 7 hours plus meeting someone before lunch almost always have something with learning problems. Or physical activity and reduced consumption of sweets have something with successful training. Perhaps this is not a mere correlation, but a causality.</p>

<p>Do your own experiments and feel like a scientist.</p>

<h2 id="step-2-mindset">Step 2: Mindset</h2>

<p><a href="https://en.wikipedia.org/wiki/Carol_Dweck">Carol Dweck</a>, Stanford University psychologist, identified two core mindsets: fixed mindset and growth mindset.</p>

<p><img src="/assets/images/learning/learning_2.png" alt="Виды мышления" /></p>

<p>Mindset is a collection of beliefs, ideas and concepts held by oneself.</p>

<p><strong>Fixed mindset</strong> is characterized by such beliefs:</p>

<ul>
  <li>I am who I am and people don’t change</li>
  <li>success relies on innate talent</li>
  <li>people fit into specific categories: techies, humanitarians, strong and weak, smart and stupid, etc.</li>
  <li>I should avoid changes and challenges to prevent the possibility of failure</li>
  <li>efforts are worthless</li>
  <li>I need to choose a path of the least effort</li>
  <li>being criticized is bad</li>
  <li>I have every right to complain about problems and failures</li>
</ul>

<p><strong>Growth</strong> <strong>mindset</strong> is characterized by such beliefs:</p>

<ul>
  <li>I’m able to change, my abilities and intelligence can be developed over time if I put my mind to it</li>
  <li>success can be achieved through effort</li>
  <li>categories of people are more likely approximate descriptions of the current state or areas of interest, they don’t define anyone’s fate</li>
  <li>I willingly embrace challenges, it’s an opportunity to grow</li>
  <li>effort leads to mastery</li>
  <li>I believe failures are just temporary setbacks and learning opportunities</li>
  <li>constructive feedback as a source of information</li>
  <li>complaints make no sense and distract from the things that really matter</li>
</ul>

<p>You can notice a recursive trap: fixed mindset makes a person think that his fate is predetermined and he won’t be able to change.</p>

<p>Studies of mindsets lead to an interesting conclusion: the quality of life and satisfaction depend more on a subjective attitude, and <em>not on talent or intelligence.</em> In other words, a person can develop a growth mindset with beliefs and rational evidence.</p>

<p>Use your emotional resistance (“probably, this is not my thing”, “it’s obvious that I’m not a tech guy…”, “I would never make it as a programmer”) as a starting point in your mindset transformation.</p>

<p>Resistance, problems and failures aren’t going anywhere. Any professional who has achieved something has thousands of times more problems and failures than a beginner who has given up. They are distinguished primarily by their attitude to these problems.</p>

<p>It’s fine to feel resistance. This is a sign of growth. Don’t miss the opportunity to grow.</p>

<h2 id="step-3-openness"><strong>Step 3: Openness</strong></h2>

<p>Forget the myth that hard work and tons of books you’ve read will make you an expert. The shortest way to get into learning stagnation is to isolate yourself from other students and teachers.</p>

<p><img src="/assets/images/learning/learning_3.png" alt="Процесс обучения" /></p>

<ol>
  <li><strong>Ask questions.</strong> If you learn programming at Hexlet you will get an answer anyway — our mentors answer all questions after each lesson. Formulating a question also helps to sort everything out and bring you closer to a solution. An abstract problem in the head and the one put into text are different things.</li>
  <li><strong>Communicate.</strong> You might call yourself an extrovert or an introvert, but every person needs socializing more or less, and this is crucial in studying. It is very helpful to find other people with similar problems to yours, to know about their progress and experience. Hexlet has a <a href="https://slack.hexlet.io">big friendly chat</a> for this purpose.</li>
  <li><strong>Accept and share your experience.</strong> Find someone who is in a similar situation or under the same conditions. Right now someone like you is trying to learn programming or a new language. Someone is experiencing similar difficulties. Consider starting your own blog.</li>
</ol>

<h2 id="step-4-progress"><strong>Step 4: Progress</strong></h2>

<p>The process of exploring new areas can sometimes seem too slow or even endless. In the essay <a href="https://rakhim.org/process-of-learning/">“The Learning Process”</a> I had an interesting analogy describing the process of learning new subjects. I recommend you to read it if you ask yourself the same questions:</p>

<ul>
  <li>Which book should I start with?</li>
  <li>I kind of understood each topic separately, but I simply don’t get how they are connected. And why did I even study it, it makes no sense to me.</li>
  <li>I study a lot but that’s not really helping!</li>
</ul>

<p><img src="/assets/images/learning/learning_4.png" alt="Пазлы" /></p>

<p>I also advise you to read Kirill Mokevnin’s article on <a href="https://hexlet.io/blog/posts/how-to-read-professional-literature-more-effectively">effective reading of professional literature.</a></p>

<p>A temporary lack of visible progress is OK but a long-lasting one is a sign of serious problems. For example, if after six months of learning programming you still can’t write and run a simple program, it’s about time to make changes to the learning process. Try as soon as possible (it doesn’t have to be perfect!) to create your own project, application, website, etc.</p>

<p>A good strategy is to keep track of progress by recording your goals, progress and successes. Review it from time to time and compare yourself with your past self. If you find past problems a little funny or you are even a bit <a href="https://hello.rakh.im/how_to_evaluate_personal_growth/">embarrassed</a> — that’s awesome! You’ve obviously grown up. If the old problems haven’t gone away, then it’s worth changing the approach, conditions and tools of training.</p>

<p>As it often happens, all such topics can be summed up in a short ancient Greek saying: γνῶθι σεαυτόν — <strong>know yourself</strong>.</p>

<h2 id="references">References</h2>

<p>I recommend you these books if you’d like to learn more about the subject:</p>

<ol>
  <li><a href="https://en.wikipedia.org/wiki/Carol_Dweck#References">Carol Dweck</a>, <a href="https://www.amazon.com/Mindset-Psychology-Carol-S-Dweck/dp/0345472322">Mindset: The New Psychology of Success</a>.</li>
  <li><a href="https://en.wikipedia.org/wiki/Mihaly_Csikszentmihalyi">Mihaly Csikszentmihalyi</a>, <a href="https://www.amazon.com/Flow-Psychology-Experience-Perennial-Classics/dp/0061339202/ref=sr_1_1?crid=2SNPIPBAN139T&amp;keywords=flow+the+psychology+of+optimal+experience&amp;qid=1650616340&amp;s=books&amp;sprefix=Flow%3A+The+Psychology+of+Optimal+Experience%2Cstripbooks-intl-ship%2C217&amp;sr=1-1">Flow: The Psychology of Optimal Experience</a>.</li>
  <li><a href="https://en.wikipedia.org/wiki/Viktor_Frankl">Viktor Frankl</a>, <a href="https://www.amazon.com/Mans-Search-Meaning-Viktor-Frankl/dp/0807014273/ref=sr_1_1?crid=1EYLE5AI3M18L&amp;keywords=Man%27s+Search+for+Meaning&amp;qid=1650616396&amp;s=books&amp;sprefix=man%27s+search+for+meaning%2Cstripbooks-intl-ship%2C210&amp;sr=1-1">Man’s Search for Meaning</a>.</li>
</ol>

              ]]>
            </turbo:content>
        </item>
        
        <item turbo="true">
            <turbo:extendedHtml>true</turbo:extendedHtml>
            <link>https://guides.hexlet.io/deploy/</link>
            <!-- <turbo:source></turbo:source> -->
            <!-- <turbo:topic>Code delivery to the production server
</turbo:topic> -->
            <title>Code delivery to the production server
</title>
            <pubDate>Tue, 29 Mar 2022 00:00:00 +0000</pubDate>
            <author>Kirill Mokevnin</author>
            <!-- <yandex:related></yandex:related> -->
            <turbo:content>
              <![CDATA[
                <div data-block="breadcrumblist">
                  <a href="https://guides.hexlet.io/">Hexlet Guides</a>
                  <a href="https://guides.hexlet.io/deploy/">Code delivery to the production server
</a>
                </div>
                <button
                  formaction="https://guides.hexlet.io/deploy/"
                  data-background-color="#eee"
                  data-color="dark"
                  data-turbo="false"
                  data-primary="false"
                >
                  Читать полную версию на сайте
                </button>
                <p>Deployment is the process of web service “deployment”, e.g. of a website, in the operating environment. An operating environment is a place where a website is started and available for requests. This can be ready-made hosting as well as your own server infrastructure.</p>

<p><em>Not only web services but also any services available over the network are deployed. Even if this network is internal and not available for requests over the Internet.</em></p>

<p>To understand deployment, you need to understand the code life cycle. The application code is built on the developer’s workstation and run in another place called production. Production is a startup environment (also called a live environment). In the case of a simple application, it may consist of a single server, but for truly complex applications it can be thousands and tens of thousands of servers.</p>

<p>How does it work? Developers add the code to the information repository. At some point, they decide it’s time to bring it to production. This can be done on a regular schedule such as every two weeks or just as needed up to the release after each change. In many cases, the number of deployments depends on the automation level, i.e. to which extent the process is easy to conduct and rollback. At Hexlet, deployments are performed almost after each change, approximately three deployments a day.</p>

<p>When developers decide now it’s time, they create a release. Release usually refers to a Git tag that marks things to be deployed. Namely, changes added to a master branch after the tag has been created won’t affect the tag itself, which means that we are sure about what we will be deploying.</p>

<!-- image -->

<p>For static websites or a separate frontend (HTML, CSS, and static files only), deployment comes down to updating the code on the server. In the case of backend deployment, the database is connected at the very least. In general, deployment can be a complicated procedure taking decent time. In distributed systems consisting of many independent web services, there is no regular deployment at all - each part of the application is deployed (released) independently.</p>

<p><em>It’s worth mentioning that such PaaS platforms as Heroku take the deployment completely upon themselves. There you just have to make a commit, and then everything will happen by itself. The price for this is the cost of the platform itself.</em></p>

<h2 id="deployment-stages">Deployment stages</h2>

<h3 id="code-delivery-to-the-server">Code delivery to the server</h3>

<p>There are different options for code delivery to the server, depending on its packaging. Sometimes the code is directly transmitted to the server as a set of files, but more often it’s updated via Git. Back in the day, the deployment method through standard package managers of Linux distributions was popular. It’s still in use today and best suited for certain situations.</p>

<ul>
  <li>Git: <em>git checkout tag-name</em></li>
  <li>Docker: <em>docker pull image-name:tag-name</em></li>
  <li>Apt (package): <em>apt-install application-package-name</em></li>
</ul>

<h3 id="database-update">Database update</h3>

<p>In general, a new application version requires changes in the database. To do this, migrations - special scripts containing database update rules - are run during (or before) deployment. For instance, SQL scripts:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">car</span> <span class="p">(</span>
    <span class="n">id</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
    <span class="n">license_plate</span> <span class="nb">VARCHAR</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
    <span class="n">color</span> <span class="nb">VARCHAR</span> <span class="k">NOT</span> <span class="k">NULL</span>
<span class="p">);</span>

<span class="k">ALTER</span> <span class="k">TABLE</span> <span class="k">owner</span> <span class="k">ADD</span> <span class="n">driver_license_id</span> <span class="nb">VARCHAR</span><span class="p">;</span>
</code></pre></div></div>

<h3 id="start-and-stop">Start and stop</h3>

<p>Somewhere in this process, the old version stops, and the new one starts. If we first stop the old version, then execute migrations and start the new version, we will get service downtime. This is a really common thing for many, but it can be sensitive for business and frequent deployments. So, the most advanced projects don’t stop during deployment. There is a description below of how to do it.</p>

<h2 id="automation">Automation</h2>

<p>Deployment should be automated as much as possible; Time To Market, a key characteristic of business-oriented applications, depends on it. The faster and more often we deliver changes to the user, the better. The faster we check hypotheses, the faster we introduce changes, and the faster the money invested in development pays its way. Developers are afraid to perform deployment without automation, it becomes a burden that leads to a decrease in deployments and regular stress for the whole team, working long hours.</p>

<p>There are three main automation ways:</p>

<ol>
  <li>Using utilities created for specific languages. For example, it’s Capistrano in Ruby, one of the first and best-known utilities of its kind, which has become popular far beyond Ruby. The main problem with such tools is strong binding with the language</li>
  <li>Using Ansible with an <a href="https://docs.ansible.com/ansible/latest/collections/community/general/deploy_helper_module.html">already built-in module for deployment</a>. It’s relevant for most deployment situations on managed servers</li>
  <li>Kubernetes-type orchestration systems. If they are used, you can’t do without automated deployment</li>
</ol>

<p>However, even if automation is executed, the task of “running deployment” remains. The start is also automated. There is a whole approach called <a href="https://en.wikipedia.org/wiki/Continuous_delivery">Continuous Delivery</a>. It’s difficult to implement and is not suitable everywhere, but if it works, you can forget about deployment. It’s performed entirely on its own without human involvement. The main thing in this option is good monitoring and alerting system.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c1"># https://docs.ansible.com/ansible/latest/collections/community/general/deploy_helper_module.html#examples</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Initialize the deploy root and gather facts</span>
  <span class="na">community.general.deploy_helper</span><span class="pi">:</span>
    <span class="na">path</span><span class="pi">:</span> <span class="s">/path/to/root</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Clone the project to the new release folder</span>
  <span class="na">ansible.builtin.git</span><span class="pi">:</span>
    <span class="na">repo</span><span class="pi">:</span> <span class="s">ansible.builtin.git://foosball.example.org/path/to/repo.git</span>
    <span class="na">dest</span><span class="pi">:</span> <span class="s1">'</span><span class="s">'</span>
    <span class="na">version</span><span class="pi">:</span> <span class="s">v1.1.1</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Add an unfinished file, to allow cleanup on successful finalize</span>
  <span class="na">ansible.builtin.file</span><span class="pi">:</span>
    <span class="na">path</span><span class="pi">:</span> <span class="s1">'</span><span class="s">/'</span>
    <span class="na">state</span><span class="pi">:</span> <span class="s">touch</span>
</code></pre></div></div>

<h2 id="zero-downtime-deployment">Zero Downtime Deployment</h2>

<p>If no special steps are taken, each deployment will cause the service to stop (possibly partially). At this time users will either see an error or a message that an update is in progress. But this does not happen on most major Internet services. Why? Due to the implementation of the “Zero Downtime Deployment” approach (downtime means service operational downtime).</p>

<p>Zero Downtime Deployment is when the service never stops running, but in the meantime, it’s being updated. This is achieved by simultaneously running the old version and the new code. Namely, when an application is deployed, the new version arises next to the old one. And only when the automatics make sure that the new version has started and run, the old version is stopped. The following is required to perform this procedure:</p>

<ol>
  <li>Infrastructure. You need a load balancing to switch traffic (incoming connections from browsers or other systems) between the old and the new version of the code. And it’s desirable to have at least two servers, although it’s not required</li>
  <li>Deployment. Zero downtime deployment process is much more complicated than the usual one. The easiest way to execute it’s on orchestration systems such as Kubernetes</li>
  <li>Code culture. It’s impossible to ensure non-stop operation without a certain culture of code writing. For the old and the new version to work simultaneously, you need to keep an eye on all interfaces. It’s important to maintain backward compatibility (working with API, database, queues, and, in general, with any storage)</li>
  <li>Database. It should be backward compatible between the old and the new versions. All migrations are forward-only (you can’t undo them!) and for addition only. You can’t delete and update (rename, change the type of) columns and tables</li>
</ol>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">extensions/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">tomcat-deployment-${TARGET_ROLE}</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">2</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">tomcat</span>
        <span class="na">role</span><span class="pi">:</span> <span class="s">${TARGET_ROLE}</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">tomcat-container</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">tomcat:${TOMCAT_VERSION}</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">8080</span>
        <span class="na">readinessProbe</span><span class="pi">:</span>
          <span class="na">httpGet</span><span class="pi">:</span>
            <span class="na">path</span><span class="pi">:</span> <span class="s">/</span>
            <span class="na">port</span><span class="pi">:</span> <span class="m">8080</span>
</code></pre></div></div>

<h2 id="links">Links</h2>

<ul>
  <li><a href="https://docs.ansible.com/ansible/latest/collections/community/general/deploy_helper_module.html">Ansible Deploy</a></li>
</ul>

              ]]>
            </turbo:content>
        </item>
        
        <item turbo="true">
            <turbo:extendedHtml>true</turbo:extendedHtml>
            <link>https://guides.hexlet.io/virtualization/</link>
            <!-- <turbo:source></turbo:source> -->
            <!-- <turbo:topic>What is Virtualization and Why is It Needed</turbo:topic> -->
            <title>What is Virtualization and Why is It Needed</title>
            <pubDate>Fri, 25 Mar 2022 00:00:00 +0000</pubDate>
            <author>Kirill Mokevnin</author>
            <!-- <yandex:related></yandex:related> -->
            <turbo:content>
              <![CDATA[
                <div data-block="breadcrumblist">
                  <a href="https://guides.hexlet.io/">Hexlet Guides</a>
                  <a href="https://guides.hexlet.io/virtualization/">What is Virtualization and Why is It Needed</a>
                </div>
                <button
                  formaction="https://guides.hexlet.io/virtualization/"
                  data-background-color="#eee"
                  data-color="dark"
                  data-turbo="false"
                  data-primary="false"
                >
                  Читать полную версию на сайте
                </button>
                <p>Linux or Mac users sometimes need to run Windows-only programs, and, in turn, Windows users, especially programmers, may need to launch Linux or another version of Windows. The classic example is Photoshop or games.</p>

<p>The most obvious way, and it’s a costly affair, is to buy a second computer. Another way is to install Windows next to your main operating system. Generally, such an installation may lead to a system crash, but once you’ve done you’ll be able to choose a system to boot. But there is a third way, <strong>virtualization</strong>.</p>

<h2 id="virtualization">Virtualization</h2>

<p><strong>Virtualization is the creation of isolated environments within a single physical device</strong> (in our case, a computer). Each environment appears to be a separate computer with unique characteristics, such as available memory, CPU, etc. This environment is called a set of logical resources or a <strong>virtual machine</strong>.</p>

<p><em>Virtualization allows you to run the operating system like a regular program right on your computer!</em></p>

<p>The OS running a virtual environment is called <strong>the host</strong> and the OS running in a virtual environment is called <strong>the guest</strong>.</p>

<p>A special program (in fact, also an OS) called <strong>a hypervisor</strong> creates and manages virtual machines. The hypervisor isolates operating systems from each other and provides protection, security, and resource allocation between running OSs. Depending on the type of virtualization, the hypervisor can work directly with the hardware without a host system, or through the main OS installed on the host machine. In the first case, we use <strong>hardware virtualization</strong>, and in the second case, <strong>software virtualization</strong>. The second is regular for home computers.</p>

<p>Unlike installing two parallel OSs in one machine, virtualization is a much more secure way. You can uninstall and reinstall the systems at any time. You can create as many virtual machines as you need.</p>

<h3 id="hardware-virtualization">Hardware virtualization</h3>

<p>As the name implies, hardware virtualization is related to the hardware, i.e. the processor. In this case, unlike software virtualization, guest operating systems are controlled directly by the hypervisor without the participation of the host OS.</p>

<p>Hardware virtualization is much more efficient than software virtualization, since the hypervisor, unlike the host OS, creates a very small overhead while software virtualization is divided into several subtypes. You can read more about it on <a href="https://en.wikipedia.org/wiki/Virtualization">Wikipedia</a>.</p>

<h3 id="container-virtualization">Container virtualization</h3>

<p><strong>Container virtualization</strong> is another matter. Unlike the previous types, it is not related to running the OS in an isolated environment. With container virtualization, isolation occurs at the OS processes level.</p>

<p>Currently, this kind of virtualization is used only in Linux and is available thanks to two kernel features: cgroups and namespaces. These features make run only one process as if it were running in its own world, with its own network, own disk, own file system, and so on. With this kind of virtualization, one process runs on <strong>the same operating system and the same kernel</strong>. For example, you cannot run Windows on Linux. This virtualization is applied at the level of service that is part of the software product. The most famous projects are OpenVZ, Docker, LXC.</p>

<h2 id="hosting">Hosting</h2>

<p>Each virtual machine receives as many resources as you specify. The hosters (companies providing web hosting services) use it a lot. In fact, each user creates his own virtual machine with limits set up by selected plan (memory, CPU, etc.).</p>

<p>In addition, virtualization isolates machines from each other, which means you don’t have to worry if users try to harm the system or neighboring users. Such a service is usually called VPS (virtual private server) and is cheap in the basic configuration.</p>

<p>Virtual machines allow you to utilize hardware resources more efficiently. Not all users need all the hardware power that the hoster has, or simply do not want to pay for it. A virtual machine can use only a part of the hardware capacity, which allows hosting dozens of clients on one machine. It’s a win-win situation: the user is satisfied, and the hoster earns his money.</p>

<h2 id="faq">FAQ</h2>

<h3 id="what-to-do-if-the-cpu-does-not-support-virtualization">What to do if the CPU does not support virtualization?</h3>

<p>It is extremely unlikely, but even in this case it is possible to start a virtual machine. However the performance will be very low, since program virtualization will be implemented instead of software virtualization. In other words, it’s better to upgrade your hardware.</p>

<!---
## Related guides

1. [What is Vagrant](/vagrant/). Vagrant allows creating and configuring lightweight, repeatable, and portable development environments for virtual machines.
2. [How to work with Linux using Windows](/ubuntu-linux-in-windows/). Instructions for installing Ubuntu Linux on Windows using various virtualization technologies.
--->

              ]]>
            </turbo:content>
        </item>
        
        <item turbo="true">
            <turbo:extendedHtml>true</turbo:extendedHtml>
            <link>https://guides.hexlet.io/check-list-of-engineering-practices/</link>
            <!-- <turbo:source></turbo:source> -->
            <!-- <turbo:topic>Checklist of Good Software Engineering Practices in Companies</turbo:topic> -->
            <title>Checklist of Good Software Engineering Practices in Companies</title>
            <pubDate>Thu, 24 Mar 2022 00:00:00 +0000</pubDate>
            <author>Kirill Mokevnin</author>
            <!-- <yandex:related></yandex:related> -->
            <turbo:content>
              <![CDATA[
                <div data-block="breadcrumblist">
                  <a href="https://guides.hexlet.io/">Hexlet Guides</a>
                  <a href="https://guides.hexlet.io/check-list-of-engineering-practices/">Checklist of Good Software Engineering Practices in Companies</a>
                </div>
                <button
                  formaction="https://guides.hexlet.io/check-list-of-engineering-practices/"
                  data-background-color="#eee"
                  data-color="dark"
                  data-turbo="false"
                  data-primary="false"
                >
                  Читать полную версию на сайте
                </button>
                <p>Software development is a challenging process that tends to become much more complex as the number of participants increases. More people in the team create more communication and require more synchronization (sharing knowledge of system parts and processes, keeping track of the business and its requirements). The cost of error increases, and the system can no longer fit in just one head, while a change to one element affects a change to the other element.</p>

<p>Different teams cope with these conditions in different ways. Some of them keep a high development pace and make regular releases, while others are slowing down significantly: their negotiations take more time than their development, their quality drops, and their version updates become stressful and adventurous. The total speed of feature implementation of one team can be way more or even ten times faster than that of other teams.</p>

<p>There are many reasons for this crucial difference. Here are some of them:</p>

<ul>
  <li>Top management regarding business. When a company does the wrong things, its efficiency does not matter – the business will eventually close down. This topic is beyond our current guide</li>
  <li>Top management regarding processes. If this level is not good, everything else is irrelevant. Even the wrong bonus structure can lead to team rifts and ultimately shut down development altogether</li>
  <li>Human factor. Personal virtues and vices can cause problems for the rest of the team and the whole project. The main problem is this part cannot be rectified by any process. It is either a behavior change or a break-up</li>
  <li>Poor development process. This applies to every engineer and includes everything from communication and task handling to testing and code review</li>
</ul>

<p>Some problems are either difficult or impossible to solve (at the developer level). But others, especially those relating to engineering practices, should be continually improved and fixed. Programmers should be very involved in this.</p>

<ul>
  <li><a href="https://en.hexlet.io/pages/recommended-books">Books</a>
    <ul>
      <li>Peopleware: Productive Projects and Teams</li>
      <li>Mythical Man-Month, The: Essays on Software Engineering</li>
      <li>The Clean Coder: A Code of Conduct for Professional Programmers</li>
      <li>The Goal: A Process of Ongoing Improvement</li>
    </ul>
  </li>
  <li><a href="https://agilemanifesto.org/iso/en/manifesto.html">Manifesto for Agile Software Development</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Bus_factor">Bus Factor</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Cargo_cult">Cargo cult</a></li>
</ul>

<p>Although there are many practices, the net result is how quickly your customers get the results of your work and how pleased they are with it. Below is a checklist to see whether the team is using those engineering practices that are considered most appropriate.</p>

<p><em>Compliance with these standards does not guarantee the company won’t have problems. It may be a cargo cult, or its processes may be so formalized that they hinder rather than help. On the other hand, there is an exception to every rule and there will always be some projects which cannot apply some of the following. Finally, some of these approaches may conflict with one’s values.</em></p>

<h2 id="coding">Coding</h2>

<p><strong>Good</strong></p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Version_control">VCS</a>. The code is put under version control (usually Git)</li>
  <li><a href="https://en.wikipedia.org/wiki/Extreme_programming_practices#Collective_code_ownership">Collective code ownership</a>. Any member of the team can change any piece of code in the system at any time</li>
  <li><a href="https://en.wikipedia.org/wiki/Extreme_programming_practices#Coding_standard">Coding standart</a>. All team members adhere to the coding standards adopted for the stack (language, platform)</li>
</ul>

<p><strong>Bad</strong></p>

<ul>
  <li>Lack of a unified style. Everyone writes code in the style they are used to. There are no common standards at all or there is one but it is absolutely different from the generally accepted rules</li>
  <li>There is no version control. Code backups are used instead, and developers have to negotiate so that they don’t overwrite each other’s changes</li>
  <li>The code has an “owner”. Developers protect their piece of code from encroachment by other team members</li>
</ul>

<p><strong>Links</strong></p>

<ul>
  <li><a href="https://trunkbaseddevelopment.com/">Trunk Based Development</a></li>
</ul>

<h2 id="development-environment">Development environment</h2>

<p><strong>Good</strong></p>

<ul>
  <li>Development (dev) environment. Development is done in a dedicated environment. This is usually a local machine (possibly using Vagrant or Docker Compose). Each developer has a unique environment, and changes in one environment can’t affect others</li>
  <li>One-click, automated deployment of the environment. This makes it easy to introduce newcomers to your project, to quickly and automatically propagate infrastructure changes and operate with no concern of crashing, as it is easy to rebuild</li>
  <li>Infrastructure as code. Configuration changes are propagated through the project code. One more dev environment deployment (with new project code) is enough to push all updates</li>
  <li>The development environment is as close to a production environment as possible. Linux running services require Linux as the development environment. The same applies to other issues</li>
</ul>

<p><strong>Bad</strong></p>

<ul>
  <li>Deploying and setting up the environment is done either with manuals or by the “try to run, read the error message, google for solution, and fix it” method. It’s expensive and inefficient. Manuals become outdated nearly the second they are written. A new person can spend days deploying the environment from scratch</li>
  <li>Manual configuration update. All developers receive some directive to make local configuration changes to the environment (e.g., add something new) for the new code to work</li>
  <li>Shared database for all developers. Loading from one person affects everyone. Crash failure also slows down everyone else</li>
</ul>

<h2 id="quality">Quality</h2>

<p><strong>Good</strong></p>

<ul>
  <li>Test coverage. Tests increase confidence in the code performance. Good tests have a positive impact on a code design. Test-covered code is usually better than untested one. Although there is a correlation</li>
  <li>A feature that has been partially tested or hasn’t been tested at all is not considered completed. Testing reduces the workload of the rest of the team and positively affects the quality of a subsequent code. Moreover, it’s best to write tests immediately, as there is often no time left for them later</li>
  <li>Developer is responsible for his feature all the way to the end. A feature is only considered completed when it is running in a production workflow. Everybody in the team must understand that the most important goal is to deliver value to the customer. As long as no one uses the feature, it doesn’t matter if it’s written, because the business is screwed at that point</li>
  <li>The team members reviewing each other’s code (to a reasonable extent). The reviewing process helps both find bugs and learn from each other</li>
  <li><a href="https://en.wikipedia.org/wiki/Pair_programming">Pair programming</a>. This is an effective approach not only for programmers but also for programmer–tester or novice–expert pair</li>
  <li><a href="https://en.wikipedia.org/wiki/Continuous_integration">Continuous integration (CI)</a>. The project repositories are connected to a CI server, where the code style is checked after each commit (by running linters), tests are run, and the project is built (e.g. compiled)</li>
  <li>Incident <a href="https://www.pagerduty.com/resources/learn/post-mortem-incident-report/">postmortems</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Retrospective#Software_development">Retrospective</a>. The process is continually improving and every team member affects the changes</li>
</ul>

<p><strong>Bad</strong></p>

<ul>
  <li>No testing. New code performance tests are done manually by clicking through. This way has disastrous consequences, such as low delivery speed and most likely poor code quality</li>
  <li>No code review. Different code styles, isolation of programmers from each other, limited sharing of experience, poor production decisions</li>
  <li>The programmer considers the feature closed when their code reaches the main branch. New code remains idle and useless and may even become obsolete before it reaches the customer</li>
  <li><a href="https://en.wikipedia.org/wiki/Performance_indicator">KPI</a>. Heavy use of quantitative metrics: lines of code, released features, closed bugs. Instead of being result-oriented, developers strive to meet KPIs. Even if it goes against business goals</li>
  <li>High degree of formalization. Speed slows down, motivation drops</li>
</ul>

<p><strong>Links</strong></p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Extreme_programming">Extreme programming</a></li>
</ul>

<h2 id="development-process">Development process</h2>

<p><strong>Good</strong></p>

<ul>
  <li>Developers are guided by <a href="https://12factor.net">12factors</a> principles. Applications are easier to deploy, scale and monitor</li>
  <li>A single test runs in a fraction of a second. Test-driven development implies frequent testing during debugging. The speed of launching a particular test is extremely important here – it should be fast enough to keep the developer on track</li>
  <li>Effortless and enjoyable test writing. It is a touchstone to determine how good the project tests are. If you have to force yourself, likely, the tests are poorly written (e.g. a lot of mocks), and there won’t be enough of them</li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Test-driven_development">Test-driven development (TDD)</a>. If possible, write tests before the code. There are several reasons why this is important:</p>

    <p>Tests require you to think not about the implementation, but about the way the code being tested will be used. Because of this approach, programmers detect flaws in their interfaces at a very early stage.</p>

    <p>The code must be tested in any case. If there is no test, it has to be checked in person.</p>
  </li>
  <li>Once a bug is detected, first a test is written to reproduce it, then a fix is made. This is the only case where tests really help</li>
</ul>

<p><strong>Bad</strong></p>

<ul>
  <li>You have tests, but you have to force yourself to write them because they are difficult to write, take a long time to run, often crash or you have to rewrite them all the time</li>
  <li>Running one test takes seconds. Such a test is hard to run in TDD and the total test execution time becomes too long</li>
  <li>The code is fixed directly in production (the place where it works). No comment</li>
</ul>

<p><strong>Links</strong></p>

<ul>
  <li><a href="https://12factor.net">12factors</a></li>
</ul>

<h2 id="new-version-release-more-relevant-to-web-projects">New version release (more relevant to web projects)</h2>

<p>The production environment is the infrastructure (e.g. servers) where the project is deployed. It provides access to the project for end users.</p>

<p>Deployment is the process of updating the project in the production environment.</p>

<p><strong>Good</strong></p>

<ul>
  <li>Automation. Deployment is automated and performed by clicking one button</li>
  <li>Frequent small releases. Deployment is routine and can be done at any time when features are ready, with no team distractions</li>
  <li>Zero Downtime Deployments. Version updates are transparent to users</li>
  <li>Technically, deployment can be done by any team member (i.e. everything is well automated)</li>
</ul>

<p><strong>Bad</strong></p>

<ul>
  <li>Manual deployment. For example, by direct management from the server. It is the most unreliable and unscalable approach, prone to error, which can take a considerable amount of time. Doesn’t work with multiple servers</li>
  <li>Deployment comes with emotional tension and involves a large number of participants. This atmosphere makes everyone tend to slow down their code deployment, which causes even more problems and hurts the business</li>
  <li>Deployment process takes dozens of minutes or hours. This likely means that the build process is integrated with the deployment. These tasks need to be done separately</li>
  <li>Deployment happens once a week or rarer. The more changes deployed at once, the greater the chance of failure. And the harder it is to track the impact of each feature on business outcomes. In addition, changes that have been made before and were waiting to be deployed to production get overlooked</li>
  <li>Long downtimes during deployment. Users have to wait for a deployment to complete. This situation interferes with frequent deployments</li>
  <li>Deployment is done by a single person. Knowledge is stored in one head. Then this person goes on vacation or getting sick, ruining the whole process, as the rest of the team don’t understand how it’s all set up</li>
  <li>Deployment of configuration. Updating a configuration outside the logic of the code (e.g. changing a database password or database address) requires a second deployment. These parameters are strictly infrastructural and should go into the code as described in Twelve-Factor App</li>
</ul>

<p><strong>Links</strong></p>

<ul>
  <li><a href="https://www.atlassian.com/devops">What is DevOps?</a></li>
</ul>

              ]]>
            </turbo:content>
        </item>
        
        <item turbo="true">
            <turbo:extendedHtml>true</turbo:extendedHtml>
            <link>https://guides.hexlet.io/version-managers/</link>
            <!-- <turbo:source></turbo:source> -->
            <!-- <turbo:topic>What is Version Manager</turbo:topic> -->
            <title>What is Version Manager</title>
            <pubDate>Wed, 23 Mar 2022 00:00:00 +0000</pubDate>
            <author>Kirill Mokevnin</author>
            <!-- <yandex:related></yandex:related> -->
            <turbo:content>
              <![CDATA[
                <div data-block="breadcrumblist">
                  <a href="https://guides.hexlet.io/">Hexlet Guides</a>
                  <a href="https://guides.hexlet.io/version-managers/">What is Version Manager</a>
                </div>
                <button
                  formaction="https://guides.hexlet.io/version-managers/"
                  data-background-color="#eee"
                  data-color="dark"
                  data-turbo="false"
                  data-primary="false"
                >
                  Читать полную версию на сайте
                </button>
                <h2 id="system-installation">System installation</h2>

<p>To run code in any language, you need to install its interpreter (or compiler). Different operating systems do it differently: some of them use package managers, for example, <em>apt</em> or <em>yum</em>, and some download the installer directly from the repository. Some languages come preinstalled with an operating system, for example, Python. In particular, Python plays a key role in the Linux OS and its distributions.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Ubuntu</span>
<span class="nb">sudo </span>apt <span class="nb">install </span>nodejs <span class="c"># installs most recent version</span>
</code></pre></div></div>
<p>The standard installation method works well only at the very beginning during the initial setup. Then, over time, different problems begin to surfase. For example, at some point, a new version of the language comes out but the project you are working on requires the latest version. Usually, it takes some time before the language becomes available for installation through package managers. And in this case, you either have to wait, which isn’t always convenient, or look for another installation method. The last one often becomes a challenge and takes a lot of time, with hours of googling and installing additional libraries. All this eventually clogs the system and sometimes breaks it.</p>

<p>Another serious problem arises when developer requires different versions of the same language for different programs. It happens surprisingly often since there are plenty of options in development: various company projects, pet-projects, open source.</p>

<p><em>It’s important thing to mention, that all of this doesn’t concern those, who have completely thrown themselves into Docker and Docker Compose. However, even in this case, languages are required to work with open source.</em></p>

<h2 id="version-managers">Version managers</h2>

<p>To solve these problems, the developers came up with version managers. A version manager is a special program designed to handle language versions. With its help it became possible to install the required versions and switch between them. Unlike the package managers that come with operating systems, version managers always allow to install the latest versions of languages as soon as they come out (including installing alpha and beta versions).</p>

<p>For example, you can use <a href="https://github.com/nvm-sh/nvm">NVM</a> (Node Version Manager) for Node.js:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Install NVM</span>
curl <span class="nt">-o-</span> https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash
<span class="c"># Installation does not mean activation. After installation, the version that was before installation will remain active</span>
nvm <span class="nb">install </span>node <span class="c"># Install the latest available version of the node</span>
nvm <span class="nb">install </span>6.14.4 <span class="c"># or 10.10.0, 8.9.1, and so on.</span>
nvm ls-remote <span class="c"># list of available versions</span>
nvm use node <span class="c"># Activate the last installed version of the node</span>
nvm use node 17 <span class="c"># Activate the required version</span>
</code></pre></div></div>
<p>To simplify the work, version managers usually enable users to create a special file within the project that captures the required version of the language. In some cases, version managers track this file and switch versions automatically.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nb">echo</span> <span class="s2">"17"</span> <span class="o">&gt;</span> .nvmrc
<span class="c"># This command spotted .nvmrc file and used the version specified there</span>
<span class="nv">$ </span>nvm use
Found <span class="s1">'/path/to/project/.nvmrc'</span> with version &lt;17&gt;
Now using node v17
</code></pre></div></div>
<p>In today’s world its hard to imagine a language without version manager. Moreover, some of the widely used languages, such as Ruby, have many competitive version managers:</p>
<ul>
  <li>go: gvm, g</li>
  <li>java: jabba</li>
  <li>ruby: rbenv, rvm, chruby</li>
  <li>php: phpenv, phpbrew</li>
  <li>python: pyenv</li>
</ul>

<p>Version managers also solve a few more important tasks. Customarily, when a programmer interacts with a language installed directly, he has to use <em>sudo</em> when installing global packages. The fact is that the standard language installation scheme is intended for all users at once. Hence, all the necessary files, including global packages, get into shared directories that require administrative rights. From the security perspective, this is a vulnerability that developers of open source libraries can exploit (and sometimes they do). Version managers install everything in the current user’s home directory, where he already has full rights. On the one hand, it allows not to run package installation as an administrator, and on the other hand, the system isn’t clogged. Version manager makes it painless to remove a language and all its packages. All you have to do is delete the directory (although it’s better to do this using the version manager tools).</p>

<h2 id="universal-version-manager">Universal version manager</h2>

<p>While solving some problems, version managers also cause a few others. Firstly, there are too many of them, so their popularity constantly changes. Secondly, the process of installing the version manager can be more complicated than installing the language. The problem is that they need to be universal and work everywhere, which is extremely problematic, considering the diversity of modern ecosystems. It’s enough to look at the size of the NVM documentation to assess the scale of the disaster. Thirdly, all these managers work differently and have different commands. It complicates the process of switching between them while working with various languages.</p>

<p>All this led to the next logical step. Eventually, a universal manager <a href="https://asdf-vm.com/">asdf</a> appeared on the scene, and, thanks to plugins, is now able to work with any language. A shortlist of its advantages:</p>

<ul>
  <li>A single command line utility to work with all languages</li>
  <li>A single interface for all languages</li>
  <li>Automatic switching between languages within each project</li>
  <li>A simple plugin system that allows to add any language</li>
</ul>

<p>Now <em>asdf</em> has become quite popular and is gradually replacing every other version managers (technically, language-specific managers are more often used there). It has a bit more complex command system due to the need to support many languages, but otherwise it significantly simplifies the whole process.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># asdf has excellent documentation, which clearly shows how to install it,</span>
<span class="c"># and what dependencies can be required in different systems</span>
<span class="c"># Installing</span>
git clone https://github.com/asdf-vm/asdf.git ~/.asdf <span class="nt">--branch</span> v0.9
<span class="c"># Restart the terminal after that</span>
<span class="nb">echo</span> <span class="s1">'. $HOME/.asdf/asdf.sh'</span> <span class="o">&gt;&gt;</span> ~/.bashrc
<span class="c"># To work with a particular language, it's necessary to install the respective plugin</span>
<span class="c"># The list of available plugins is on the project website</span>
asdf plugin add nodejs
<span class="c"># Language installing</span>
<span class="c"># Instead of nodejs, you need to substitute the name of the plugin you are working with</span>
asdf <span class="nb">install </span>nodejs latest <span class="c"># latest means the latest version of the required language</span>
<span class="c"># Installing the required version</span>
asdf <span class="nb">install </span>nodejs latest
<span class="c"># Installing the required language version by default</span>
asdf global nodejs latest
<span class="c"># Shows current language versions installed through asdf</span>
asdf current
elixir         1.10.1-otp-22 <span class="o">(</span><span class="nb">set </span>by /Users/user/.tool-versions<span class="o">)</span>
erlang         22.2.7   <span class="o">(</span><span class="nb">set </span>by /Users/user/.tool-versions<span class="o">)</span>
nodejs         17.0.0   <span class="o">(</span><span class="nb">set </span>by /Users/user/.tool-versions<span class="o">)</span>
php            7.4.5    <span class="o">(</span><span class="nb">set </span>by /Users/user/.tool-versions<span class="o">)</span>
python         3.8.2 2.7.16 <span class="o">(</span><span class="nb">set </span>by /Users/user/.tool-versions<span class="o">)</span>
ruby           2.7.0    <span class="o">(</span><span class="nb">set </span>by /Users/user/.tool-versions<span class="o">)</span>
yarn           1.22.4   <span class="o">(</span><span class="nb">set </span>by /Users/user/.tool-versions<span class="o">)</span>
</code></pre></div></div>
<h2 id="conclusion">Conclusion</h2>

<p>Working with different versions of the language is a challenge, which is made easy due to version managers and Docker (for advanced users). Among all managers, <em>asdf</em> stands out and at the same time becomes a universal tool for managing any language and even regular programs.</p>

              ]]>
            </turbo:content>
        </item>
        
        <item turbo="true">
            <turbo:extendedHtml>true</turbo:extendedHtml>
            <link>https://guides.hexlet.io/how-to-search/</link>
            <!-- <turbo:source></turbo:source> -->
            <!-- <turbo:topic>How to search for technical information</turbo:topic> -->
            <title>How to search for technical information</title>
            <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
            <author>Kirill Mokevnin</author>
            <!-- <yandex:related></yandex:related> -->
            <turbo:content>
              <![CDATA[
                <div data-block="breadcrumblist">
                  <a href="https://guides.hexlet.io/">Hexlet Guides</a>
                  <a href="https://guides.hexlet.io/how-to-search/">How to search for technical information</a>
                </div>
                <button
                  formaction="https://guides.hexlet.io/how-to-search/"
                  data-background-color="#eee"
                  data-color="dark"
                  data-turbo="false"
                  data-primary="false"
                >
                  Читать полную версию на сайте
                </button>
                <p><strong>One of the most important skills for a programmer is the ability to find answers and solve problems using Google. A lot of the problems that beginners face have already been solved and described before. All you need is to learn how to find these solutions and answers.</strong></p>

<h2 id="websites">Websites</h2>

<p>The main sites to get your questions answered:</p>
<ul>
  <li><a href="https://github.com">GitHub</a></li>
  <li><a href="https://stackoverflow.com">Stackoverflow</a></li>
</ul>

<h2 id="language">Language</h2>

<p>As practice shows, at the beginning most programmers try to search for information in their native language. Sometimes you can find the answer this way, but more often — no. <strong>The universal language for programmers is English</strong> – the whole world speaks it. The amount of information in the English-speaking segment is noticeably higher than in any other. Besides it’s a lot fresher. Learn to formulate your thoughts more accurately, and while searching - compose a set of words in English. This way you will master the terminology faster.</p>
<div class="fs-3 border-start p-4 mb-3 bg-light border-info border-3 banner">
    <a href="https://ru.code-basics.com/?utm_source=hexlet-guides&amp;utm_medium=banner&amp;utm_campaign=site-code-basics" target="_blank">Code Basics: бесплатные курсы программирования
</a>
</div>

<h2 id="search-engine">Search engine</h2>

<p>To continue the previous section it’s important to note that the best way to search for information is using Google. Although local search engines are fine for certain tasks, the English-speaking segment isn’t their main market, and they are much inferior to Google. For example, you will notice that after a while Google adapts to your queries and starts showing more relevant links. It can understand which programming language you prefer and will output the related answers.</p>

<p>Another important point: Google search works even better than site search. If you need something, for example, on Github, it’s better to make the proper Google query to get a better and faster result. The below section “query language” provides further details.</p>

<h2 id="query-language">Query language</h2>

<p>Each search engine has a query language. It includes special search operators allowing you to specify more precisely what you want. Here are a few common search techniques:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">site:stackoverflow.com how to test react code</code> — this search will be performed through <a href="https://stackoverflow.com/">Stackoverflow</a>.</li>
  <li><code class="language-plaintext highlighter-rouge">add class to element -jquery</code> — a hyphen denotes stop words, therefore, all variants excluding these words will be found.</li>
  <li><code class="language-plaintext highlighter-rouge">"immutable js"</code> — double quotes indicating to look for an exact match.</li>
</ul>

<p>The full list can be found <a href="https://support.google.com/websearch/answer/2466433?visit_id=1-636424030566191968-2246914586&amp;p=adv_operators&amp;hl=en&amp;rd=1">on the Google support site</a>.</p>

<h2 id="library-search">Library search</h2>

<p>The vast majority of libraries are located (they say, “hosted”) on <a href="https://github.com">GitHub</a>. Let’s say you need to find a library for executing HTTP requests in JavaScript. To do this you can form the following request: <code class="language-plaintext highlighter-rouge">github js http client</code>. Google will show you a dozen links to different repositories. Of course, you can also use the query language: <code class="language-plaintext highlighter-rouge">site:github.com js http client</code>, but generally it’s enough to simply indicate <code class="language-plaintext highlighter-rouge">github</code>.
The same search strategy can be used for well-known libraries: <code class="language-plaintext highlighter-rouge">github express</code>.</p>

<h2 id="search-by-error-message">Search by error message</h2>

<p>Before you search by error message, it’s necessary to understand where <em>the error message</em> is here exactly. Although the output contains a lot of relevant information, it’s not a description of this error. For example:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code>There was 1 failure:
1<span class="o">)</span> App<span class="se">\S</span>olutionTest::testResult with data <span class="nb">set</span> <span class="c">#2 (0, 2, 2, 1, 2)</span>
Failed asserting that <span class="s1">'1'</span> matches expected 0.
/usr/src/app/tests/App/Tests/SolutionTest.php:15
FAILURES!
Tests: 3, Assertions: 3, Failures: 1.
Makefile:2: recipe <span class="k">for </span>target <span class="s1">'test'</span> failed
make: Leaving directory <span class="s1">'/usr/src/app'</span>
make: <span class="k">***</span> <span class="o">[</span><span class="nb">test</span><span class="o">]</span> Error 1
</code></pre></div></div>

<p>The output has a lot of text but there is only one real error message: <code class="language-plaintext highlighter-rouge">Failed asserting that '1' matches expected 0.</code>. In this particular case, it’s approximately clear what is wrong and where to look (the file and line are indicated in the stack trace below). But so happens not always. If you correctly identified the error message, you may also want to do one thing. Often such messages are personalized: they take specific values of parameters that relate to your environment. For example, paths to files. Hence, if you search throughout the error message, then most likely Google won’t find anything. For example, in the message above, such parameters are <code class="language-plaintext highlighter-rouge">'1'</code> and <code class="language-plaintext highlighter-rouge">0</code>. If you clear the phrase, there will be <code class="language-plaintext highlighter-rouge">Failed asserting that matches expected</code>. That’s what you have to look for. You can also add language name: <code class="language-plaintext highlighter-rouge">php Failed asserting that matches expected</code>.</p>

<h2 id="behavior-search">Behavior search</h2>

<p>Sometimes an error message is either missing or cannot lead to a correct answer (since it’s a consequence, not a cause). At this point, you need to be creative and make a sentence in English. A set of keywords will also work. If the search wasn’t successful then try to add <code class="language-plaintext highlighter-rouge">site:stackoverflow.com</code>. Stackoverflow is a unique place having answers to almost all similar questions.
If you know which library or program exactly the error belongs to, it would be useful to find its repository on Github and study the Issues section. If there definitely is an error, and it’s relevant, then most certainly someone has already mentioned it.</p>

<h2 id="official-documentation">Official documentation</h2>

<p>Search is good but don’t forget to look into the official documentation for tools (including programming languages). Official (and not only) documentation, as a rule, is divided into following types:</p>

<ol>
  <li><a href="https://guides.rubyonrails.org/getting_started.html">Getting Started</a> is a small (not always) step-by-step guide helping to create a minimal working version and quickly start working with the tool to see it in action. It’s the first document you need to look for.</li>
  <li><a href="https://laravel.com/docs/5.5/routing">Guides</a> are descriptions of the tool components. They are written in a narrative form, so it’s not hard to read them from start to finish. They make it easier to learn large blocks of information.</li>
  <li><a href="https://bit.ly/2uq98XM">API</a> is a concise documentation on all possible application functions. It is more intended for finding answers to specific questions.</li>
  <li><a href="https://blog.codeship.com/an-introduction-to-apis-with-phoenix/">Tutorials</a>, in contrast to quides, are aimed at various options for using the tool.</li>
</ol>

              ]]>
            </turbo:content>
        </item>
        
        <item turbo="true">
            <turbo:extendedHtml>true</turbo:extendedHtml>
            <link>https://guides.hexlet.io/error-tracking/</link>
            <!-- <turbo:source></turbo:source> -->
            <!-- <turbo:topic>What is Error Tracking?</turbo:topic> -->
            <title>What is Error Tracking?</title>
            <pubDate>Fri, 18 Mar 2022 00:00:00 +0000</pubDate>
            <author>Kirill Mokevnin</author>
            <!-- <yandex:related></yandex:related> -->
            <turbo:content>
              <![CDATA[
                <div data-block="breadcrumblist">
                  <a href="https://guides.hexlet.io/">Hexlet Guides</a>
                  <a href="https://guides.hexlet.io/error-tracking/">What is Error Tracking?</a>
                </div>
                <button
                  formaction="https://guides.hexlet.io/error-tracking/"
                  data-background-color="#eee"
                  data-color="dark"
                  data-turbo="false"
                  data-primary="false"
                >
                  Читать полную версию на сайте
                </button>
                <p>There are no programs without errors. Their number can be reduced with the great help of a type system, linters, tests, or even a whole department of testers, but it’s impossible to remove them completely. This is the reality we must face; the best thing we can do is learning how to track these errors and fix them as soon as possible.</p>

<h2 id="how-you-shouldnt-work-with-errors">How you shouldn’t work with errors</h2>

<p>It’s quite common in development: programmers write some code, release a new version of a website or application and move on. In the meantime, some users start experiencing problems: something freezes or crashes, issues with sending forms out, data being displayed incorrectly, and so on. This may last long enough for someone to lose patience and finally complain to the support service. Then, along the chain, it makes it to the programmers, and they try to find the root cause behind the error, when it began or who caused the bug to happen. The clarification of all the details begins, and most likely with the participation of users who are willing to help. With this approach, a huge number of errors remain unnoticed for a very long time, and the worst part is that users leave. Can we avoid this? Clearly, we can.</p>

<h2 id="how-to-work-with-errors">How to work with errors</h2>

<p>There are plenty of services called Error Trackers. They collect information about occurring errors in real time and notify the development team. These services integrate with a multitude of available platforms, from televisions to mobile applications and websites (both frontend and backend).</p>

<p><img src="/assets/images/error-tracking/rollbar-dashboard.jpg" alt="Rollbar Dashboard" /></p>

<p>Above is a screenshot of a dashboard service <a href="https://rollbar.io/">rollbar.io</a> which we use for all our Hexlet projects. You can track the frequency of critical errors in the last 24 hours for each project. This graph with performance metrics helps you diagnose issues immediately. Below is the output of specific project’s errors. According to the icons, most of the errors are caused by JavaScript.</p>

<p><img src="/assets/images/error-tracking/rollbar-project.jpg" alt="Rollbar Project" /></p>

<p>Each such service provides libraries for different languages and platforms, they are usually added to the code and called on in case of errors. These libraries send not just the error but also additional useful information about the environment. Such information may include data about users, their browsers, application settings, and more.</p>

<p>Ideally, that kind of library is already <a href="https://docs.rollbar.com/docs/rails">integrated</a> into a framework, for example, Rails. Then you hardly have to configure anything. You just connect the library to the framework as a plugin and it will start detecting errors by itself, without extra interaction. If there is no such integration, well.. then you’ll have to write some code to link your application to the library. You can find more information on how to do this in the service documentation. <a href="https://docs.rollbar.com/docs/react">Here</a> is an example of Rollbar integrated into React. Once the connection is successfully established, the detected error will look like this:</p>

<p><img src="/assets/images/error-tracking/rollbar-error.jpg" alt="Rollbar Error" /></p>

<p>If we take a closer look at the top menu, we can see that tabs provide very useful information about errors.</p>

<p>But detecting an error is only half of it. You then need to notify the team somehow without flooding everyone with spam. The thing is that errors usually don’t occur just once. If it’s a common error and the number of users is high, then you can easily catch one error thousands of times per minute. And if there is a notification for each occurrence (by email or in Slack), then such a service wouldn’t work for long.</p>

<p><img src="/assets/images/error-tracking/rollbar-notifications.jpg" alt="Rollbar Error" /></p>

<p>That’s why such trackers work more effectively. When the error occurs for the first time, the service notifies the development team with real-time alerts so that they can quickly address it. If it happens once again, then no more alerts. At least not every time. For example, alerts can be sent at the first, tenth, hundredth, thousandth and so on as they occur. This is the first part. Further, after updating the application version, trackers label errors as “corrected”. This makes it much easier to track errors that developers either forgot to fix or did not fix properly. Most often, alerts start pouring in after the deployment. In order to prevent future issues, you need to notify the tracker service about deploys. You can read more about this in the <a href="https://docs.rollbar.com/docs/deploy-tracking">documentation area</a> of the relevant tracker.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Error trackers are very important tools, and it’s hard to imagine production without using them. At that one of many services or specialized software can act as an error  tracker (for example, <a href="https://github.com/getsentry/sentry">Sentry</a>), a service installed on servers in case of high security requirements.</p>

              ]]>
            </turbo:content>
        </item>
        
        <item turbo="true">
            <turbo:extendedHtml>true</turbo:extendedHtml>
            <link>https://guides.hexlet.io/docker/</link>
            <!-- <turbo:source></turbo:source> -->
            <!-- <turbo:topic>Why and How to Use Docker?</turbo:topic> -->
            <title>Why and How to Use Docker?</title>
            <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
            <author>Kirill Mokevnin</author>
            <!-- <yandex:related></yandex:related> -->
            <turbo:content>
              <![CDATA[
                <div data-block="breadcrumblist">
                  <a href="https://guides.hexlet.io/">Hexlet Guides</a>
                  <a href="https://guides.hexlet.io/docker/">Why and How to Use Docker?</a>
                </div>
                <button
                  formaction="https://guides.hexlet.io/docker/"
                  data-background-color="#eee"
                  data-color="dark"
                  data-turbo="false"
                  data-primary="false"
                >
                  Читать полную версию на сайте
                </button>
                <p><strong>Docker is a program that allows the operating system to run processes in an isolated environment based on specially created images. And, while the technologies underlying Docker existed earlier, it was Docker that changed the way we now build project infrastructure, assemble and launch services.</strong></p>

<p><em>(Some details were purposefully left out of the article to avoid unnecessary information).</em></p>

<h2 id="installation">Installation</h2>

<p>To start with Docker, you must first install the Docker Engine. Download links for all popular platforms are provided at https://docs.docker.com/engine/install/. Select yours and install Docker.</p>

<p>There’s one thing to remember when installing Docker on Mac and Linux. By default, Docker runs through a non-networked UNIX socket. For security reasons, the socket is blocked for users who are not members of the docker group. Although the installer automatically adds the current user to this group, Docker will not work straight away. In reality, changing the group by the user has no effect till the user logs in again. This is a feature of the core. Enter the <code class="language-plaintext highlighter-rouge">id</code> command to see which groups your user belongs to.</p>

<p>You can check if the installation was successful with the <code class="language-plaintext highlighter-rouge">docker info</code> command:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker info
Containers: 22
 Running: 2
 Paused: 0
 Stopped: 20
Images: 72
Server Version: 17.12.0-ce
Storage Driver: overlay2
 Backing Filesystem: extfs
 Supports d_type: <span class="nb">true
 </span>Native Overlay Diff: <span class="nb">true
</span>Logging Driver: json-file
Cgroup Driver: cgroupfs
...
</code></pre></div></div>

<p>It provides quite a lot of information about Docker configurations as well as work statistics.</p>

<h2 id="launch">Launch</h2>

<p>At this stage, the execution commands are given with no explanation. Later, more information on how they’re formed and what include will be given.</p>

<p>Let’s start with the easiest one:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker run <span class="nt">-it</span> nginx bash
root@a6c26812d23b:/#
</code></pre></div></div>

<p>This command will begin downloading the <em>nginx</em> image on the initial call, so you will have to wait a few moments. After the image is downloaded, <em>bash</em> will run, and you will find yourself <strong>in a container</strong>.</p>

<p>Go through the file system, and look at the <em>/etc/nginx</em>. As you can see, its content does not match what you have on your system. This file system was generated by the <em>nginx</em> image. Everything you do within it will not affect your main file system. With the <code class="language-plaintext highlighter-rouge">exit</code> command, you can get back to your native system.</p>

<p>Now, let’s call the <code class="language-plaintext highlighter-rouge">cat</code> command, which is already in another container but is also launched from the <em>nginx</em> image:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker run nginx <span class="nb">cat</span> /etc/nginx/nginx.conf

user  nginx<span class="p">;</span>
worker_processes  1<span class="p">;</span>

error_log  /var/log/nginx/error.log warn<span class="p">;</span>
pid        /var/run/nginx.pid<span class="p">;</span>
...
<span class="err">$</span>
</code></pre></div></div>

<p>The command is executed almost instantly since the image has already been uploaded. Unlike before, when a bash script and an interactive session were launched in the container, the <code class="language-plaintext highlighter-rouge">cat /etc/nginx/nginx.conf</code> command for the <em>nginx</em> image will display the contents of the specified file (taken from the running container’s file system) and return control to where you were before. You won’t end up inside the container.</p>

<p>The last launch option will be:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Note that no command is specified after the image name</span>
<span class="c"># This approach works if the launch command is written in the image</span>
<span class="nv">$ </span>docker run <span class="nt">-p</span> 8080:80 nginx
</code></pre></div></div>

<p>This command does not restore control, because Nginx starts running. Enter <code class="language-plaintext highlighter-rouge">localhost:8080</code> into your browser. You’ll see that the <em>Welcome to nginx!</em> page has loaded!. If you return to the terminal where the container was launched, you’ll see a log of requests to <code class="language-plaintext highlighter-rouge">localhost:8080</code>. You may stop nginx by pressing <kbd>Ctrl + C</kbd>.</p>

<p>Although each launch was different and resulted in various outcomes, the overall pattern of their work is consistent. Docker downloads the image automatically (the first argument after <code class="language-plaintext highlighter-rouge">docker run</code>) and, if necessary, runs the container with the specified command.</p>

<p><strong>An image is an independent file system</strong>. For now, we use ready-made images, but we will eventually learn how to create them ourselves.</p>

<p><strong>A container is a running process of the operating system in an isolated environment</strong> with an image file system.</p>

<p>A container is, once again, just a usual operating system process. The main difference is that Docker starts the process in an isolated environment due to the kernel’s capabilities (details in the end). The container sees its own process list, network, file system, and so forth. Unless otherwise specified, it cannot interact with your main operating system or anything stored or launched there.</p>

<p>Try running the <code class="language-plaintext highlighter-rouge">docker run -it ubuntu bash</code> command and typing <code class="language-plaintext highlighter-rouge">ps auxf</code> inside the running container. The output will be as follows:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code>USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.1  0.1  18240  3300 pts/0    Ss   15:39   0:00 /bin/bash
root        12  0.0  0.1  34424  2808 pts/0    R+   15:40   0:00 ps aux
</code></pre></div></div>

<p>There are only two processes, and the process ID of Bash is 1. To ensure that the <em>/home</em> directory is empty, you may use the <code class="language-plaintext highlighter-rouge">ls /home</code> command. Also, check out that the <code class="language-plaintext highlighter-rouge">root</code> user is the default one inside the container.</p>

<h2 id="whats-all-this-for">What’s all this for?</h2>

<p><strong>Docker is a general-purpose tool for delivering applications to machines (local computers or remote servers) and running them in an isolated environment.</strong></p>

<p>Remember the process when you had to build programs from the source. It’s likely to consist of the following steps:</p>

<ul>
  <li>Install all of the operating system dependencies (finding them is quite a task)</li>
  <li>Download the archive, unpack it</li>
  <li>Start configuration <code class="language-plaintext highlighter-rouge">make configure</code></li>
  <li>Start compilation <code class="language-plaintext highlighter-rouge">make compile</code></li>
  <li>Install <code class="language-plaintext highlighter-rouge">make install</code></li>
</ul>

<p>As you can see, the process is not always straightforward or quick, and in certain cases, it may even be impossible because of cryptic issues (not to mention the corruption of the operating system).</p>

<p>Docker simplifies this method by allowing you to run a single command with a near-perfect success rate. Look at a fictional example in which the Tunnel program is installed on a local computer in the <em>/usr/local/bin</em> directory. It uses the <em>tunnel</em> image:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code>docker run <span class="nt">-v</span> /usr/local/bin:/out tunnel
</code></pre></div></div>

<p>This command moves the program’s executable file from the <em>tunnel</em> image in the <em>/usr/local/bin</em> directory on the main system. The <code class="language-plaintext highlighter-rouge">docker run</code> command launches a container from the <em>tunnel</em> image. The program is compiled locally and eventually ends up in the <em>/usr/local/bin</em> directory of the main file system. You may now run the program by typing <code class="language-plaintext highlighter-rouge">tunnel</code> in the terminal.</p>

<p>What if the program we are installing has dependencies? The secret is that the container was launched from a fully equipped image. It includes all necessary dependencies and ensures approximately 100% operability regardless of the status of the main OS.</p>

<p>It is not always necessary to copy a program from a container to your main system. It is enough to launch the container only when you need it. Assume we decided to create a static website using Jekyll. Jekyll is a popular static website generator written in Ruby, and even this guide is generated using it and Docker as well.</p>

<p>Earlier you have had to install at least Ruby and Jekyll itself as a gem on your main system (gem is the name of packages in Ruby). Furthermore, as with all such things, Jekyll only works with particular versions of Ruby, which leads to its own configuration issues.</p>

<p>Running Jekyll with Docker is reduced to just a single command executed in the blog directory (you can examine our guides <a href="https://github.com/hexletguides/hexletguides.github.io">repository</a>):</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code>docker run <span class="nt">--rm</span> <span class="nt">--volume</span><span class="o">=</span><span class="s2">"</span><span class="nv">$PWD</span><span class="s2">:/srv/jekyll"</span> <span class="nt">-it</span> jekyll/jekyll jekyll server
</code></pre></div></div>

<p>In the same way, a huge number of different software products are being launched at the moment. The further away, the more this approach takes over the world. Now, we dip into the origin of the name Docker.</p>

<p><img src="/assets/images/docker/docker_logo.png" alt="docker logo" /></p>

<p>As you know, ships are the leading way to distribute goods around the world. Previously, the cost of transportation was high, because each cargo had its own shape and type of material.</p>

<p><img src="/assets/images/docker/cargo.jpg" alt="loading cargo onto a ship" /></p>

<p>Loading a bag of fish or a car onto a ship are different tasks requiring different processes and tools. There were problems with loading methods that required a variety of cranes and tools. And, given the ship’s fragility, securely loading cargo on board was a challenging procedure.</p>

<p>But at some point, everything changed. The following picture says more than a thousand words:</p>

<p><img src="/assets/images/docker/container_terminal.jpg" alt="shipping container terminal" /></p>

<p>Containers have equalized all types of cargo and standardized loading and unloading tools around the world, which in turn led to a simplification of processes, acceleration, and, therefore, lower costs.</p>

<p>The same thing happened in software development. Docker has become a universal software delivery tool, regardless of its structure, dependencies, or installation method. All that is required for programs distributed via Docker is that they are contained within the image and do not interact with the main system or other containers. The importance of this fact cannot be overestimated. Now, updating software versions does not involve either the system itself or other programs. Nothing can break anymore. All you need to do is download a new image of the program you want to update. In other words, Docker removed the <a href="https://en.wikipedia.org/wiki/Dependency_hell">dependency hell</a> problem and made the infrastructure <a href="https://martinfowler.com/bliki/ImmutableServer.html">immutable</a>.</p>

<p>Given the existence of numerous configuration tools (chef, puppet, ansible) prior to the Docker era, server management was somewhat daunting. The main cause of all problems was the mutable state. Programs are installed, updated, and deleted. This happens at different times and in somewhat different ways on different servers. Updating the version of a language like PHP, Ruby, or Python, for example, could be quite an adventure with a total loss of workability. It’s much easier to put a new server next to it and switch to it. In theory, Docker allows you to make such a switch. Because each running container exists in its own environment, it is best to forget about the old one and replace it with a new one. Moreover, the rollback in such a system is pretty superficial: all you need is to stop the new container and rebuild the old one using the previous image.</p>

<h2 id="application-in-a-container">Application in a container</h2>

<p>Let’s now discuss how an application corresponds to a container. There are two possible approaches:</p>

<ol>
  <li>The entire application is a container, inside which a process tree unfolds: an application, a web server, a database, and so on</li>
  <li>Every running container is an atomic service. In other words, each container, whether a web server or an application, is a single program</li>
</ol>

<p>In fact, only the second approach provides access to all of Docker’s advantages. Firstly, services are usually split over numerous servers and moved between them (for example, when a server crashes). Secondly, updating one service shouldn’t lead to stopping the others.</p>

<p>The first approach is extremely rare, yet sometimes required. Hexlet, for example, works in two modes. The website and its services follow the second model, in which each service is distinct, but for practical exercises performed in a browser, we follow the principle of “one user — one container.” Depending on the exercise, anything can be placed inside the container. At least, the Hexlet IDE itself always starts there, and it in turn generates terminals (processes). A database is launched in the same container in our database course, and a web server is launched in a web-related course. This method creates the illusion of working on a genuine machine and makes it simpler to maintain work with exercises. Just to be clear, you probably won’t require our use case, which is highly unique.</p>

<p>Another important aspect when working with containers relates to the state. For example, if the database is launched in a container, then its data should never be stored within the container. A container can be easily destroyed because it is an operating system process, and its existence is never permanent. Docker includes tools for storing and accessing data from the main file system. We’ll get to them later.</p>

<h2 id="working-with-images">Working with images</h2>

<p>Docker is more than just a program. This is an entire ecosystem with many projects and services. The main service you will have to work with is Registry, an image storage.</p>

<p>Generally, it works the same way as the package repository of any package manager. You can view its contents on the website <a href="https://hub.docker.com/">https://hub.docker.com/</a>, by clicking Explore.</p>

<p>When we run the <em>run</em> <code class="language-plaintext highlighter-rouge">docker run &lt;image name&gt;</code> command, Docker checks for the presence of the specified image on the local machine and downloads it if necessary. The list of images already downloaded to your computer can be displayed with the <code class="language-plaintext highlighter-rouge">docker images</code> command:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker images
REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE
workshopdevops_web                   latest              cfd7771b4b3a        2 days ago          817MB
hexletbasics_app                     latest              8e34a5f631ea        2 days ago          1.3GB
mokevnin/rails                       latest              96487c602a9b        2 days ago          743MB
ubuntu                               latest              2a4cca5ac898        3 days ago          111MB
Ruby                                 2.4                 713da53688a6        3 weeks ago         687MB
Ruby                                 2.5                 4c7885e3f2bb        3 weeks ago         881MB
nginx                                latest              3f8a4339aadd        3 weeks ago         108MB
elixir                               latest              93617745963c        4 weeks ago         889MB
postgres                             latest              ec61d13c8566        5 weeks ago         287MB
</code></pre></div></div>

<p>Let’s figure out how the image name is formed, and what it includes.</p>

<p>The second column in the output above is called TAG. The <code class="language-plaintext highlighter-rouge">docker run nginx</code> command is, in fact, a shortcut for the <code class="language-plaintext highlighter-rouge">docker run nginx:latest</code> which was executed. That is, we do not just download the <em>nginx</em> image, but its particular version. The latest is the default tag. It’s easy to guess that it means the latest version of the image.</p>

<p>It is essential to understand that this is just an agreement, not a rule. A specific image may or may not have the <em>latest</em> tag, but it will not contain the most recent changes just because no one publishes them. ВPopular images, on the other hand, follow the agreement. As it is clear from the context, tags in Docker are changeable; that is, no one guarantees that downloading an image with the same tag on different computers at different times will result in the same thing. This approach may seem strange and unreliable because there are no guarantees, but in practice, there are certain agreements that all popular images follow. The latest tag always contains the most recent version and is constantly updated, but <a href="https://semver.org/">semantic versioning</a> is also actively used. Let’s have a look at https://hub.docker.com/_/nginx</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="syntax"><code>1.13.8, mainline, 1, 1.13, latest
1.13.8-perl, mainline-perl, 1-perl, 1.13-perl, perl
1.13.8-alpine, mainline-alpine, 1-alpine, 1.13-alpine, alpine
1.13.8-alpine-perl, mainline-alpine-perl, 1-alpine-perl, 1.13-alpine-perl, alpine-perl
1.12.2, stable, 1.12
1.12.2-perl, stable-perl, 1.12-perl
1.12.2-alpine, stable-alpine, 1.12-alpine
1.12.2-alpine-perl, stable-alpine-perl, 1.12-alpine-perl
</code></pre></div></div>

<p>Tags with the complete semantic version (x.x.x) are always immutable, even if they contain something else, such as <em>1.12.2-alphine</em>. This version is safe to use in the production environment. When the path version changes, tags such as <em>1.12</em> are updated. That is, there may be version <em>1.12.2</em> inside the image, followed by <em>1.12.8</em> in the future. The same applies to versions that merely specify the major version, for example, <em>1</em>. Only in this case, the update is not only on the patch but also on the minor version.</p>

<p>As you may recall, the <code class="language-plaintext highlighter-rouge">docker run</code> command downloads the image if it is not available locally, but this check has nothing to do with updating the content. In short, if the <em>nginx:latest</em> has been updated, <code class="language-plaintext highlighter-rouge">docker run</code> will not download it; instead, it will use the <em>latest</em>, that is already downloaded. Another command for guaranteed image updates is <code class="language-plaintext highlighter-rouge">docker pull</code>. It always checks whether the image has been updated for a certain tag.</p>

<p>Along with tags, the image name can include a prefix, such as <code class="language-plaintext highlighter-rouge">etsy/chef</code>. This prefix is the service account name that is used to create images for the Registry. The majority of the images have a prefix, but there’s still a small set, literally a hundred images, with no prefix at all. These images are special since they are supported by Docker itself. Therefore, if there is no prefix in the image name, this is an official image. You can check their list: https://github.com/docker-library/official-images/tree/master/library</p>

<p>Images can be deleted with the <code class="language-plaintext highlighter-rouge">docker rmi &lt;imagename&gt;</code> command.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker rmi Ruby:2.4
Untagged: Ruby:2.4
Untagged: Ruby@sha256:d973c59b89f3c5c9bb330e3350ef8c529753ba9004dcd1bfbcaa4e9c0acb0c82
</code></pre></div></div>

<p>If Docker has at least one container from the removed image, then it will not allow to delete it for obvious reasons. If you still want to delete both the image and all containers associated with it, use the <code class="language-plaintext highlighter-rouge">-f</code> flag.</p>

<h2 id="container-management">Container management</h2>

<p><img src="/assets/images/docker/docker-container-lifecycle.png" alt="Docker Container LifeCycle" /></p>

<p>The picture describes the life cycle (finite state machine) of the container. The circles depict the states, the console commands are highlighted in bold, and the squares show what is actually being executed.</p>

<p>Follow the path of the  <code class="language-plaintext highlighter-rouge">docker run</code> command. This single command performs two actions in Docker: creating a container and starting it. There are more complex execution scenarios, but in this section, we will consider only the basics.</p>

<p>Let’s run nginx so that it works in the background. To do this, we will add the <code class="language-plaintext highlighter-rouge">-d</code> flag after the word <em>run</em>:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:80 nginx
431a3b3fc24bf8440efe2bca5bbb837944d5ae5c3b23b9b33a5575cb3566444e
</code></pre></div></div>

<p>After executing the command, Docker return control and outputs the container ID. Make sure that nginx is working by opening <code class="language-plaintext highlighter-rouge">localhost:8080</code> in browser. Unlike the previous launch, our nginx works in the background, which means its output (logs) is not visible. You can view it using the <code class="language-plaintext highlighter-rouge">docker logs</code> command, which requires the container ID:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker logs 431a3b3fc24bf8440efe2bca5bbb837944d5ae5c3b23b9b33a5575cb3566444e

172.17.0.1 - - <span class="o">[</span>19/Jan/2018:07:38:55 +0000] <span class="s2">"GET / HTTP/1.1"</span> 200 612 <span class="s2">"-"</span> <span class="s2">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36"</span> <span class="s2">"-"</span>
</code></pre></div></div>

<p>You can also open a log pager using <code class="language-plaintext highlighter-rouge">tail -f</code>. To do this, run <code class="language-plaintext highlighter-rouge">docker logs -f 431a3b3fc24bf8440efe2bca5bbb837944d5ae5c3b23b9b33a5575cb3566444e</code>. The log will now be updated every time you refresh the page in the browser. You can exit this mode by pressing <kbd>Ctrl + C</kbd>, but the container will not stop.</p>

<p>Now we will output information about the running containers with the <code class="language-plaintext highlighter-rouge">docker ps</code> command:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code>CONTAINER ID        IMAGE                            COMMAND                  CREATED             STATUS              PORTS                                          NAMES
431a3b3fc24b        nginx                            <span class="s2">"nginx -g 'daemon of…"</span>   2 minutes ago       Up 2 minutes        80/tcp                                         wizardly_rosalind
</code></pre></div></div>

<p>Columns description:</p>

<ul>
  <li>CONTAINER_ID — container identifier. Just like Git, Docker uses an abbreviated hash entry</li>
  <li>IMAGE — the name of the image that is used to create this container. If no tag is specified, then the latest is implied <em>latest</em> is implied</li>
  <li>COMMAND — a command that was executed at the start of the container</li>
  <li>CREATED — container creation time</li>
  <li>STATUS — current state</li>
  <li>PORTS — port forwarding</li>
  <li>NAMES — unique names. In addition to the identifier, Docker allows you to specify a name. It’s much easier to handle the container this way. If the name is not provided when creating the container, Docker will generate a random one. Like the one, Nginx has in the output above</li>
</ul>

<p>(<em>The <code class="language-plaintext highlighter-rouge">docker stats</code> command gives information about running containers’ resource consumption).</em></p>

<p>Let’s try to stop the container now. Run the following command:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c"># Instead of CONTAINER_ID, you can specify a name</span>
<span class="nv">$ </span>docker <span class="nb">kill </span>431a3b3fc24b <span class="c"># docker kill wizardly_rosalind</span>
431a3b3fc24b
</code></pre></div></div>

<p>If you type <code class="language-plaintext highlighter-rouge">docker ps</code>, you won’t see this container, it has been deleted.</p>

<p>The <code class="language-plaintext highlighter-rouge">docker ps</code> command outputs only running containers. However, there may be some stopped ones as well. Moreover, they can stop both upon successful completion and in case of errors. Try typing <code class="language-plaintext highlighter-rouge">docker run ubuntu ls</code>, followed by <code class="language-plaintext highlighter-rouge">docker run ubuntu bash -c "unknown"</code>. These commands do not initiate a long-running process. Instead, the first one terminates immediately after execution, and the second with an error, because such a command does not exist.</p>

<p>The <code class="language-plaintext highlighter-rouge">docker ps -a</code> command will now output all containers. The first three lines of output will be:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code>CONTAINER ID        IMAGE                            COMMAND                  CREATED                  STATUS                       PORTS                                          NAMES
85fb81250406        ubuntu                           <span class="s2">"bash -c unkown"</span>         Less than a second ago   Exited <span class="o">(</span>127<span class="o">)</span> 3 seconds ago                                                  loving_bose
c379040bce42        ubuntu                           <span class="s2">"ls"</span>                     Less than a second ago   Exited <span class="o">(</span>0<span class="o">)</span> 9 seconds ago                                                    determined_thatchar
</code></pre></div></div>

<p>Here are our two most recent launches. If you look at the STATUS column, you can see that both containers are in the Exited state. That is, the running command inside them was executed, and they stopped. The only difference is that one completed successfully (0), and the other did not (127). Even after it has been stopped, the container can be restarted:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code>docker start determined_thatchar <span class="c"># In your case, there will be another name</span>

</code></pre></div></div>

<p>Only this time you won’t see the output. Use the <code class="language-plaintext highlighter-rouge">docker logs determined_thatchar</code> command to see it.</p>

<h2 id="interactionbetween-thecomponentsof-asystem">Interaction between the components of a system</h2>

<p>Running an isolated container that exists entirely within itself is useless. In general, the container must interact with the outside world, accept incoming requests to a specific port, execute requests to other services, read shared files, and write to them. When you create a container, you can configure all of these features.</p>

<h3 id="interactive-mode">Interactive mode</h3>

<p>As shown, the simplest way to use Docker is to create a container and execute some commands inside it:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker run ubuntu <span class="nb">ls</span> /usr
bin
games
include
lib
<span class="nb">local
</span>sbin
share
src
<span class="err">$</span>
</code></pre></div></div>

<p>Docker returns control after executing the command, and we are no longer inside the container. If we try to run bash in the same way, we will not get what we expected:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker run ubuntu bash
<span class="err">$</span>
</code></pre></div></div>

<p>The thing is that <code class="language-plaintext highlighter-rouge">bash</code> starts an interactive session within the container. To interact with it, keep the STDIN stream open and the TTY running (pseudo-terminal). Therefore, to start interactive sessions, make sure to include the <code class="language-plaintext highlighter-rouge">-i</code> and <code class="language-plaintext highlighter-rouge">-t</code> options. They are typically added together as <code class="language-plaintext highlighter-rouge">-it</code>. So, the correct way to start bash is <code class="language-plaintext highlighter-rouge">docker run -it ubuntu bash</code>.</p>

<h3 id="ports">Ports</h3>

<p>If you run Nginx usint the <code class="language-plaintext highlighter-rouge">docker run nginx</code>command, it will be unable to accept any request, even though it listens to port <em>80</em> inside the container (let me remind you that each container exists in its own network by default). But if you run it like this: <code class="language-plaintext highlighter-rouge">docker run -p 8080:80 nginx</code>, then nginx will start responding on port <em>8080</em>.</p>

<p>The <code class="language-plaintext highlighter-rouge">-p</code> flag specifies how and which ports should be exposed to the outside. The format <code class="language-plaintext highlighter-rouge">8080:80</code> stands for “expose port <em>8080</em> inside the container to port <em>80</em> outside the container”. Furthermore, port <em>8080</em> s by default listened to on <code class="language-plaintext highlighter-rouge">0.0.0.0</code>, that is, on all available interfaces. As a result, the container launched this way is accessible not only via <code class="language-plaintext highlighter-rouge">localhost:8080</code> but also from outside the machine (if access is not denied somehow else). If you only need to do a <em>loopback</em>, the command is <code class="language-plaintext highlighter-rouge">docker run -p 127.0.0.1:8080:80 nginx</code>.</p>

<p>Docker allows you to forward an unlimited number of ports. In the case of Nginx, for example, it is frequently necessary to use both ports <code class="language-plaintext highlighter-rouge">80</code> and <code class="language-plaintext highlighter-rouge">443</code> for HTTPS. You can do it this way: <code class="language-plaintext highlighter-rouge">docker run -p 80:80 -p 443:443 nginx</code>. You can read about the other ways to forward ports in the official documentation.</p>

<h3 id="volumes">Volumes</h3>

<p>Accessing the main file system is another common task. When launching nginx container, for example, you may provide the configuration that is stored on the main fs (file system). Docker will forward it in the internal fs for Nginx to read and use.</p>

<p>The <code class="language-plaintext highlighter-rouge">-v</code>option is used for forwarding. Here’s how to start a bash session from an Ubuntu image by connecting the command history from the main file system: <code class="language-plaintext highlighter-rouge">docker run -it -v ~/.bash_history:/root/.bash_history ubuntu bash</code>. The history will be displayed if you press the up arrow in the open bash-shell. You can forward both files and directories. Any changes made inside the volume have an effect both inside and outside the container, and all operations are available by default. The number of files and directories that can be forwarded is unlimited, just like the number of ports.</p>

<p>There are some key rules to remember when working with Volumes:</p>

<ul>
  <li>The path to the file in the external system must be absolute</li>
  <li>If the inner path (what follows <code class="language-plaintext highlighter-rouge">:</code>) does not exist, Docker will create all the necessary directories and files. If it does, Docker will replace the old one with the one that was forwarded</li>
</ul>

<p>Docker provides various other options for building and using Volumes, in addition to forwarding a part of the fs outside. Read the official documentation for further details.</p>

<h3 id="environment-variables">Environment variables</h3>

<p>The application in a container is often configured via environment variables following <a href="https://12factor.net">12factors</a>. There are two ways of installing them:</p>

<ul>
  <li>The <code class="language-plaintext highlighter-rouge">-e</code> flag is used as follows: <code class="language-plaintext highlighter-rouge">docker run -it -e "HOME=/tmp" ubuntu bash</code></li>
  <li>The <code class="language-plaintext highlighter-rouge">--env-file</code> option inserts a special file containing environment variable definitions into the</li>
</ul>

<h2 id="preparing-your-own-docker-image">Preparing your own docker image</h2>

<p>Creating and publishing your own image is as simple as using it. The whole process is divided into three steps:</p>

<ul>
  <li>Create <code class="language-plaintext highlighter-rouge">Dockerfile</code> in the project’s root. The process of creating an image should be described inside</li>
  <li>Build the image using the <code class="language-plaintext highlighter-rouge">docker build</code> command</li>
  <li>Publish the image to Registry with the <code class="language-plaintext highlighter-rouge">docker push</code> command</li>
</ul>

<p>Let’s consider the image creation process by the example of packaging the <code class="language-plaintext highlighter-rouge">eslint</code> linter (do not forget to repeat it by yourself). As a result, we will have an image that can be used as follows:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker run <span class="nt">-it</span> <span class="nt">-v</span> /path/to/js/files:/app my_account_name/eslint

/app/index.js
  3:6  error  Parsing error: Unexpected token

  1 | import path from <span class="s1">'path'</span><span class="p">;</span>
  2 |
<span class="o">&gt;</span> 3 | path<span class="o">(</span><span class="p">;</span><span class="o">)</span>
    |      ^
  4 |

✖ 1 problem <span class="o">(</span>1 error, 0 warnings<span class="o">)</span>
</code></pre></div></div>

<p>So, simply run the container from this image by attaching the directory with the js files to the internal directory <em>/app</em> as Volume.</p>

<h3 id="1-the-following-is-the-final-directory-structure-with-the-files-from-which-the-image-will-be-constructed">1. The following is the final directory structure with the files from which the image will be constructed:</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="syntax"><code>eslint-docker/
    Dockerfile
    eslintrc.yml
</code></pre></div></div>

<p>The <em>eslintrc.yml</em> file contains the linter configuration. It is read automatically if it’s in the home directory and named <em>.eslintrc.yml</em>. That is, this file should be placed in the image’s <em>/root</em> directory under this name.</p>

<h3 id="2-dockerfile">2. Dockerfile</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="syntax"><code># Dockerfile
FROM node:9.3

WORKDIR /usr/src

RUN npm install -g eslint babel-eslint
RUN npm install -g eslint-config-airbnb-base eslint-plugin-import

COPY eslintrc.yml /root/.eslintrc.yml

CMD ["eslint", "/app"]
</code></pre></div></div>

<p>Dockerfile has quite a simple format. An instruction (directive) and its description are stated on each line.</p>

<h4 id="from">FROM</h4>

<p>The Dockerfile FROM instruction is required to set the base image to inherit from. It is important to note here that the images are based on each other and together form a big tree.</p>

<p>The <em>busybox</em> image can be found at the root of this tree. Because Docker provides ready-to-use images for each ecosystem and stack, it is not directly used in applied tasks.</p>

<h4 id="run">RUN</h4>

<p>The main Dockerfile instruction. In fact, we will state the <em>sh</em> command that will be run within the environment here. When creating an image, it is typically specified in the FROM instruction. Since by default everything is executed from the <em>root</em> user, there is no need to <em>sudo</em> (and most likely it is not in the base image). Also, keep in mind that building an image is not an interactive process. When using a command that potentially requires something from the user, it is necessary to hide its output. In the case of package managers, for example, they do the following: <code class="language-plaintext highlighter-rouge">apt-get install -y curl</code>. The <code class="language-plaintext highlighter-rouge">-y</code> flag indicates that installation should proceed without additional questions.</p>

<p>A Docker image is technically a set of so-called layers rather than a single file. Each RUN call creates a new layer, which can be viewed as a collection of files generated and updated (including deletion) by the RUN command. By caching unchanged layers, you can significantly improve system performance. On the other hand, Docker reuses layers in different images if they are identical, reducing both download speed and disk space occupied. The subject of layers cache is quite important when extensively using Docker. To get the most of it, you must first grasp how it works and how to precisely define the <code class="language-plaintext highlighter-rouge">RUN</code> instructions.</p>

<h4 id="copy">COPY</h4>

<p>The COPY instruction, as the name implies, copies a file or directory from the main fs to the image. But the transferred files should be in the same directory as the Dockerfile. We generally use this instruction to pack an application in an image.</p>

<h4 id="workdir">WORKDIR</h4>

<p>Sets the working directory. All subsequent instructions will be assumed to be executed from it. By default, the <code class="language-plaintext highlighter-rouge">WORKDIR</code> instruction acts like a <code class="language-plaintext highlighter-rouge">cd</code> command. Besides, when we launch the container, it also starts from the working directory. For example, by running bash, you will end up inside it.</p>

<h4 id="cmd">CMD</h4>

<p>The same instruction that defines the <code class="language-plaintext highlighter-rouge">docker run</code> default action. It is only used if the container was launched without a command; otherwise, it is ignored.</p>

<h3 id="3-building">3. Building</h3>

<p>To create a docker image, use the <code class="language-plaintext highlighter-rouge">docker build</code> command. Use <code class="language-plaintext highlighter-rouge">-t</code> flag to provide the image name, including the account name and tag. As usual, if you do not specify the tag, then the <em>latest</em> will be set.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker build <span class="nt">-t</span> my_account_name/eslint <span class="nb">.</span>
</code></pre></div></div>

<p>After running this command, the current image will be listed in the <code class="language-plaintext highlighter-rouge">docker images</code>. You can even start using it, there is no need to publish it to Registry. Let me remind you that the <code class="language-plaintext highlighter-rouge">docker run</code> command does not search for an updated version of the image if an image with the same name and tag already exist locally.</p>

<h3 id="4-publishing">4. Publishing</h3>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nv">$ </span>docker push my_account_name/eslint
</code></pre></div></div>

<p>To complete the publishing, you must meet two conditions:</p>

<ul>
  <li>Register on Docker Cloud and create a repository for the image there</li>
  <li>Log in to the CLI interface using the <code class="language-plaintext highlighter-rouge">docker login</code> command.</li>
</ul>

<h2 id="docker-compose">Docker Compose</h2>

<p>Docker Compose is a tool that allows you to develop a project locally using Docker. It is similar to Vagrant in its purpose.</p>

<p>Docker Compose also helps to manage a set of containers, each of which is a separate project service. Management includes building, dependency-aware launch, and configuration. Docker Compose configuration is specified in the <code class="language-plaintext highlighter-rouge">docker-compose.yml</code> file at the project roo. It looks as follows:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c1"># https://github.com/hexlet-basics/hexlet_basics</span>

<span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">3.3'</span>

<span class="na">services</span><span class="pi">:</span>
  <span class="na">db</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">postgres</span>
  <span class="na">app</span><span class="pi">:</span>
    <span class="na">build</span><span class="pi">:</span>
      <span class="na">context</span><span class="pi">:</span> <span class="s">services/app</span>
      <span class="na">dockerfile</span><span class="pi">:</span> <span class="s">Dockerfile</span>
    <span class="na">command</span><span class="pi">:</span> <span class="s">mix phx.server</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">${PORT}:${PORT}"</span>
    <span class="na">env_file</span><span class="pi">:</span> <span class="s1">'</span><span class="s">.env'</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">./services/app:/app:cached"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">~/.bash_history:/root/.bash_history:cached"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">.bashrc:/root/.bashrc:cached"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">/var/tmp:/var/tmp:cached"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">/tmp:/tmp:cached"</span>
    <span class="na">depends_on</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">db</span>
</code></pre></div></div>

<h2 id="in-action">In action</h2>

<p>Setting up project machines with Docker usually comes down to installing Docker. Then you just have to deploy. The basic process is:</p>

<ol>
  <li>Download a new image</li>
  <li>Stop the old container</li>
  <li>Build a new one</li>
</ol>

<p>This process does not depend on the technology stack. You can deploy (as well as configure machines) using <a href="https://docs.ansible.com/ansible/2.5/modules/docker_container_module.html">Ansible</a>.</p>

<p>Another option, suitable for more complex projects, is to use special orchestration tools such as <a href="https://kubernetes.io/">Kubernetes</a>. It generally requires extensive preparation, including an understanding of how distributed systems operate.</p>

<h2 id="docker-whats-under-the-hood">Docker: what’s under the hood?</h2>

<p>Docker’s isolation is provided by the <a href="https://en.wikipedia.org/wiki/Cgroups">Cgroups</a> and <a href="https://en.wikipedia.org/wiki/Linux_namespaces">Namespaces</a> kernel features. They enable you to run an operating system process not just in an isolated environment, but also with limited use of hardware resources (RAM or CPU).</p>

              ]]>
            </turbo:content>
        </item>
        
    </channel>
</rss>
